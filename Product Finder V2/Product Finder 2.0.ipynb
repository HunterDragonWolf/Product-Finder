{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdde864-47b8-4982-b3fb-4bf5ec4b262d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What the Product Finder version 1 does is:\n",
    "\n",
    "###### Creates a graphical user interface (GUI) for finding the most similar PDF to a given image or PDF using both text and image content similarity. Each seperately.\n",
    "\n",
    "### The Version 2 aims at combining the two logics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941bf2d1-f19b-4e70-96c2-8f13b8c6fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from threading import Thread\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load more advanced Sentence-BERT model\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')  # Larger model for better text similarity\n",
    "\n",
    "# Use ResNet-101 for better image feature extraction\n",
    "resnet_model = models.resnet101(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Preprocessing pipeline for images\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 for ResNet\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Use multiprocessing for parallel image extraction\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert image to RGB\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet-101.\"\"\"\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates cosine similarity between two image feature vectors.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints using SIFT.\"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = rgb2gray(np.array(image1))\n",
    "    image2_gray = rgb2gray(np.array(image2))\n",
    "    \n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    return len(matches)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text by removing punctuation, lowercasing, and lemmatizing.\"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "def generate_ngrams(text, n=3):\n",
    "    \"\"\"Generates trigrams from text.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "def compute_embedding(text):\n",
    "    \"\"\"Computes the embeddings of text using Sentence-BERT.\"\"\"\n",
    "    sentences = text.split('. ')\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    \"\"\"Computes the cosine similarity score between two sets of embeddings.\"\"\"\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.max().item()\n",
    "\n",
    "def process_pdf(file_info, input_embedding, input_image_features, update_progress, total_pdfs, weight_text=0.7, weight_image=0.3):\n",
    "    \"\"\"Processes a PDF file to calculate text and image similarity.\"\"\"\n",
    "    input_pdf_path, pdf_path, idx = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    trigrams = generate_ngrams(folder_pdf_text, 3)\n",
    "    enriched_text = ' '.join([folder_pdf_text] + trigrams)\n",
    "    folder_pdf_embedding = compute_embedding(enriched_text)\n",
    "    \n",
    "    # Text similarity\n",
    "    text_similarity = compute_similarity(input_embedding, folder_pdf_embedding)\n",
    "    \n",
    "    # Image similarity\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "    highest_image_similarity = -1\n",
    "    \n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "        keypoint_match_count = match_keypoints(img, img)\n",
    "        combined_image_score = similarity + (keypoint_match_count / 1000)\n",
    "        \n",
    "        if combined_image_score > highest_image_similarity:\n",
    "            highest_image_similarity = combined_image_score\n",
    "\n",
    "    # Combine weighted scores\n",
    "    combined_similarity = (text_similarity * weight_text) + (highest_image_similarity * weight_image)\n",
    "    \n",
    "    # Update progress\n",
    "    progress = (idx + 1) / total_pdfs * 100\n",
    "    update_progress(progress)\n",
    "    \n",
    "    return (pdf_path, combined_similarity)\n",
    "\n",
    "def find_most_similar_pdf(input_pdf_path, input_image_path, folder_path, update_progress, weight_text=0.7, weight_image=0.3):\n",
    "    \"\"\"Finds the most similar PDF considering both text and image similarity.\"\"\"\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    trigrams = generate_ngrams(input_text, 3)\n",
    "    enriched_text = ' '.join([input_text] + trigrams)\n",
    "    input_embedding = compute_embedding(enriched_text)\n",
    "\n",
    "    input_image = Image.open(input_image_path)\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    \n",
    "    folder_pdfs = [os.path.join(folder_path, pdf) for pdf in os.listdir(folder_path) if pdf.endswith('.pdf')]\n",
    "    total_pdfs = len(folder_pdfs)\n",
    "    \n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_pdf = {executor.submit(process_pdf, (input_pdf_path, pdf, idx), input_embedding, input_image_features, update_progress, total_pdfs): pdf for idx, pdf in enumerate(folder_pdfs)}\n",
    "        for future in future_to_pdf:\n",
    "            results.append(future.result())\n",
    "    \n",
    "    # Find PDF with the highest combined similarity\n",
    "    most_similar_pdf = max(results, key=lambda x: x[1])\n",
    "    \n",
    "    return most_similar_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f1e7b-a747-424e-8d60-58ec0b557e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
