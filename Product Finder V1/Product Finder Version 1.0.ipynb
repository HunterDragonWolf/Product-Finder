{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46486192-fcbf-4314-98fe-f2dbbc5dd00e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic PDF Questioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f5101c-5618-4e70-b8e8-241cccc1b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1270lm\n",
      "Delivered Lumens\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to answer questions from the extracted text\n",
    "def answer_question_from_text(text, question):\n",
    "    # Load a pre-trained QA model from Hugging Face\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    # Use the QA model to find the answer\n",
    "    answer = qa_pipeline(question=question, context=text)\n",
    "    return answer['answer']\n",
    "\n",
    "# Usage example\n",
    "pdf_path = \"D://Cross Search Automation//Previous Cross//VL63425 Spec Sheet.pdf\"  # Replace with the path to your PDF file\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "question = \"Total Lumens\"  # Replace with your question\n",
    "answer = answer_question_from_text(text, question)\n",
    "\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31810e26-8224-4b1c-bef5-af0b03e32da5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Improvements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef3886-a827-4b19-a45a-5718f16fada4",
   "metadata": {},
   "source": [
    "But the following code is not providing the desirable results for the second pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b76428f-2d69-478a-994e-9315ab15f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from PDF 1: 10 year\n",
      "Answer from PDF 2: 120 minute\n",
      "Similarity Ratio between PDF 1 and PDF 2: 0.02\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to answer questions from the extracted text\n",
    "def answer_question_from_text(text, question):\n",
    "    # Load a pre-trained QA model from Hugging Face\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    # Use the QA model to find the answer\n",
    "    answer = qa_pipeline(question=question, context=text)\n",
    "    return answer['answer']\n",
    "\n",
    "# Function to compare two texts and return similarities/differences\n",
    "def compare_texts(text1, text2):\n",
    "    # Use SequenceMatcher to compute a similarity ratio\n",
    "    similarity_ratio = SequenceMatcher(None, text1, text2).ratio()\n",
    "    return similarity_ratio\n",
    "\n",
    "# Main function to handle the comparison and QA\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your PDF files\n",
    "    pdf_path1 = 'Linear Emergency Egress Light 1.pdf'   # Replace with the path to the first PDF file\n",
    "    pdf_path2 = 'ol2 mullion mount.pdf'  # Replace with the path to the second PDF file\n",
    "\n",
    "    # Extract text from both PDFs\n",
    "    text1 = extract_text_from_pdf(pdf_path1)\n",
    "    text2 = extract_text_from_pdf(pdf_path2)\n",
    "\n",
    "    # Ask a question to one of the PDFs (you can choose which one)\n",
    "    question = \"What is the warranty duration?\"  # Replace with your question\n",
    "    answer_from_pdf1 = answer_question_from_text(text1, question)\n",
    "    answer_from_pdf2 = answer_question_from_text(text2, question)\n",
    "\n",
    "    print(f\"Answer from PDF 1: {answer_from_pdf1}\")\n",
    "    print(f\"Answer from PDF 2: {answer_from_pdf2}\")\n",
    "\n",
    "    # Compare texts from both PDFs\n",
    "    similarity = compare_texts(text1, text2)\n",
    "    print(f\"Similarity Ratio between PDF 1 and PDF 2: {similarity:.2f}\")\n",
    "\n",
    "    # Optional: Output differences or other comparisons as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5892f-51d0-431b-882d-d73014f32564",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74e8c9-3c70-4ad8-a0b0-67926e108725",
   "metadata": {},
   "source": [
    "Updated code, in leu of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ba66c-892e-4c3b-a8a8-9b86f9c1619f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c972ed81-104e-4613-bf26-6fb436afed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from PDF 1: 10 year\n",
      "Answer from PDF 2: 120 minute\n",
      "Similarity Ratio between PDF 1 and PDF 2: 0.02\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "from difflib import SequenceMatcher\n",
    "from pdfminer.high_level import extract_text\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text using OCR\n",
    "def extract_text_from_image(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        text += pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces)\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Function to answer questions from the extracted text\n",
    "def answer_question_from_text(text, question):\n",
    "    # Load a pre-trained QA model from Hugging Face\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    # Use the QA model to find the answer\n",
    "    answer = qa_pipeline(question=question, context=text)\n",
    "    return answer['answer']\n",
    "\n",
    "# Function to compare two texts and return similarities/differences\n",
    "def compare_texts(text1, text2):\n",
    "    # Use SequenceMatcher to compute a similarity ratio\n",
    "    similarity_ratio = SequenceMatcher(None, text1, text2).ratio()\n",
    "    return similarity_ratio\n",
    "\n",
    "# Main function to handle the comparison and QA\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your PDF files\n",
    "    pdf_path1 = 'Linear Emergency Egress Light 1.pdf'   # Replace with the path to the first PDF file\n",
    "    pdf_path2 = 'ol2 mullion mount.pdf'  # Replace with the path to the second PDF file\n",
    "\n",
    "    # Extract text from both PDFs (consider using OCR if PDFs are scanned)\n",
    "    text1 = extract_text_from_pdf(pdf_path1)\n",
    "    text2 = extract_text_from_pdf(pdf_path2)\n",
    "\n",
    "    # Optionally, if text extraction is not accurate, use OCR\n",
    "    # text2 = extract_text_from_image(pdf_path2)\n",
    "\n",
    "    # Preprocess texts\n",
    "    text1 = preprocess_text(text1)\n",
    "    text2 = preprocess_text(text2)\n",
    "\n",
    "    # Ask a question to one of the PDFs (you can choose which one)\n",
    "    question = \"What is the warranty duration?\"  # Replace with your question\n",
    "    answer_from_pdf1 = answer_question_from_text(text1, question)\n",
    "    answer_from_pdf2 = answer_question_from_text(text2, question)\n",
    "\n",
    "    print(f\"Answer from PDF 1: {answer_from_pdf1}\")\n",
    "    print(f\"Answer from PDF 2: {answer_from_pdf2}\")\n",
    "\n",
    "    # Compare texts from both PDFs\n",
    "    similarity = compare_texts(text1, text2)\n",
    "    print(f\"Similarity Ratio between PDF 1 and PDF 2: {similarity:.2f}\")\n",
    "\n",
    "    # Optional: Output differences or other comparisons as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2677a-ae01-4b53-8fa9-8872eb7343a4",
   "metadata": {},
   "source": [
    "The code is still not working as per requirements. Another attempt is made below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78070b41-1c01-482b-a68d-7d4f47bcb6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from PDF 1: 662187549422\n",
      "Answer from PDF 2: +1 844-533-4546\n",
      "Cosine Similarity between PDF 1 and PDF 2: 0.90\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to answer questions from the extracted text\n",
    "def answer_question_from_text(text, question):\n",
    "    # Load a pre-trained QA model from Hugging Face\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    # Use the QA model to find the answer\n",
    "    answer = qa_pipeline(question=question, context=text)\n",
    "    return answer['answer']\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Main function to handle the comparison and QA\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your PDF files\n",
    "    pdf_path1 = \"D://Cross Search Automation//Previous Cross//IKIO Lights//Delphi_PL_2x4FT_504030W_504035K_DLC_TDS.pdf\"   # Replace with the path to the first PDF file\n",
    "    pdf_path2 = \"D://Cross Search Automation//Previous Cross//IKIO Lights//Delphi_PL_2x2FT_403020W_504035K_DLC_TDS.pdf\"  # Replace with the path to the second PDF file\n",
    "\n",
    "    # Extract text from both PDFs\n",
    "    text1 = extract_text_from_pdf(pdf_path1)\n",
    "    text2 = extract_text_from_pdf(pdf_path2)\n",
    "\n",
    "    # Preprocess texts\n",
    "    text1 = preprocess_text(text1)\n",
    "    text2 = preprocess_text(text2)\n",
    "\n",
    "    # Ask a question to one of the PDFs (you can choose which one)\n",
    "    question = \"Wattage?\"  # Replace with your question\n",
    "    answer_from_pdf1 = answer_question_from_text(text1, question)\n",
    "    answer_from_pdf2 = answer_question_from_text(text2, question)\n",
    "\n",
    "    print(f\"Answer from PDF 1: {answer_from_pdf1}\")\n",
    "    print(f\"Answer from PDF 2: {answer_from_pdf2}\")\n",
    "\n",
    "    # Compare texts from both PDFs using cosine similarity\n",
    "    similarity = compare_texts(text1, text2)\n",
    "    print(f\"Cosine Similarity between PDF 1 and PDF 2: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac415c5-e001-4d17-b7ef-b0ff1a1af7c2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07569c93-6056-41a0-a02e-0d1618583f76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backbone 1: Now, an attempt to find similar pdf in folder based on text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ea635-2a7b-4906-873b-58cc2249323a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec37098-39c5-44e6-8ec5-516f2bd2fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Delphi_FPCL_PS.pdf with a similarity score of 0.30\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to find the most similar PDF in a folder\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "\n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "\n",
    "    # Iterate over each PDF in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            # Extract text from the current PDF\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            # Compute similarity\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "            # Update most similar PDF if needed\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "    \n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfc1d5b9-8e59-4011-a9f2-2ea331354998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Delphi_BLPL_PS.pdf with a similarity score of 0.57\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Initialize the Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Use a lightweight model for fast performance\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to find the most similar PDF in a folder using Sentence-BERT embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    input_embedding = model.encode(input_text, convert_to_tensor=True)\n",
    "\n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "\n",
    "    # Iterate over each PDF in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            # Extract and preprocess text from the current PDF\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            folder_pdf_embedding = model.encode(folder_pdf_text, convert_to_tensor=True)\n",
    "            \n",
    "            # Compute cosine similarity using Sentence-BERT\n",
    "            similarity = util.pytorch_cos_sim(input_embedding, folder_pdf_embedding).item()\n",
    "\n",
    "            # Update most similar PDF if needed\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//configurable-cpx.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "    \n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a06e770-485b-4c8f-8dc7-bf4e2d8e2f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of 0.89\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to encode text using BERT model\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the [CLS] token's embedding as the sentence representation\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Function to find the most similar PDF in a folder using BERT embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    input_embedding = encode_text(input_text)\n",
    "\n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "\n",
    "    # Preprocess all PDFs in the folder and batch encode\n",
    "    pdf_embeddings = {}\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    for filename in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "        pdf_embeddings[filename] = encode_text(folder_pdf_text)\n",
    "\n",
    "    # Compute cosine similarity for each PDF against the input PDF\n",
    "    for filename, folder_pdf_embedding in pdf_embeddings.items():\n",
    "        similarity = cosine_similarity(input_embedding, folder_pdf_embedding).item()\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "    \n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c37a5067-9ecb-456a-9259-3b75630ad62f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of 0.87\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the BERT model for NER and Sentence-BERT for embeddings\n",
    "ner_model = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_blocks = []\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text_blocks.extend(page.get_text(\"blocks\"))  # Extract text by blocks (headings, paragraphs, etc.)\n",
    "    return text_blocks\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Function to categorize and extract key entities from text\n",
    "def extract_key_sections(text_blocks):\n",
    "    sections = {'headlines': [], 'specifications': []}\n",
    "    for block in text_blocks:\n",
    "        text = block[4]\n",
    "        text = preprocess_text(text)\n",
    "        # Using heuristic: short and uppercase texts as headlines\n",
    "        if len(text.split()) <= 10 and text.isupper():\n",
    "            sections['headlines'].append(text)\n",
    "        elif len(text.split()) > 10:\n",
    "            # Apply NER for extracting specifications\n",
    "            entities = ner_model(text)\n",
    "            specifications = [entity['word'] for entity in entities if entity['entity'].startswith(\"B-\")]  # Get only Beginning of entities\n",
    "            sections['specifications'].extend(specifications)\n",
    "    return sections\n",
    "\n",
    "# Function to encode sections into embeddings\n",
    "def encode_sections(sections):\n",
    "    all_text = sections['headlines'] + sections['specifications']\n",
    "    embeddings = embedding_model.encode(all_text)\n",
    "    return embeddings\n",
    "\n",
    "# Function to find the most similar PDF in a folder using enhanced embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text_blocks = extract_text_from_pdf(input_pdf_path)\n",
    "    input_sections = extract_key_sections(input_text_blocks)\n",
    "    input_embedding = encode_sections(input_sections)\n",
    "\n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "\n",
    "    # Preprocess all PDFs in the folder and compute embeddings\n",
    "    pdf_embeddings = {}\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    for filename in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        folder_pdf_text_blocks = extract_text_from_pdf(pdf_path)\n",
    "        folder_pdf_sections = extract_key_sections(folder_pdf_text_blocks)\n",
    "        folder_pdf_embedding = encode_sections(folder_pdf_sections)\n",
    "        pdf_embeddings[filename] = folder_pdf_embedding\n",
    "\n",
    "    # Compute cosine similarity for each PDF against the input PDF\n",
    "    for filename, folder_pdf_embedding in pdf_embeddings.items():\n",
    "        similarity = cosine_similarity([input_embedding.mean(axis=0)], [folder_pdf_embedding.mean(axis=0)]).item()  # Mean pooling to get document-level similarity\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//configurable-cpx.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "    \n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc541ca-616d-4fce-bdb6-286f31c0ee38",
   "metadata": {},
   "source": [
    "The final most similar pdf on the basis of text is now here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfd65bc2-58d8-4e1d-aae9-c44624d1a409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: T8_Tube_Type_C_PS.pdf with a similarity score of 0.82\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the Sentence-BERT model once at the start\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation, convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    \n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "# Function to generate n-grams from text\n",
    "def generate_ngrams(text, n=2):\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "# Function to compute embeddings\n",
    "def compute_embedding(text):\n",
    "    # Split text into smaller chunks for more granular embeddings\n",
    "    sentences = text.split('. ')\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "# Function to compute similarity score between two sets of embeddings\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.max().item()  # Use max similarity across chunks\n",
    "\n",
    "# Function to process a single PDF file and calculate its similarity score\n",
    "def process_pdf(file_info):\n",
    "    input_embedding, input_pdf_path, pdf_path = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(folder_pdf_text, 2)\n",
    "    enriched_text = ' '.join([folder_pdf_text] + bigrams)  # Concatenate original text with bigrams\n",
    "    \n",
    "    folder_pdf_embedding = compute_embedding(enriched_text)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    similarity = compute_similarity(input_embedding, folder_pdf_embedding)\n",
    "    return (pdf_path, similarity)\n",
    "\n",
    "# Function to find the most similar PDF in a folder using Sentence-BERT embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(input_text, 2)\n",
    "    enriched_text = ' '.join([input_text] + bigrams)  # Concatenate original text with bigrams\n",
    "    \n",
    "    input_embedding = compute_embedding(enriched_text)\n",
    "\n",
    "    # List all PDF files in the folder\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_pdf, [(input_embedding, input_pdf_path, pdf_path) for pdf_path in pdf_files])\n",
    "\n",
    "    # Process results to find the most similar PDF\n",
    "    for pdf_path, similarity in results:\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = os.path.basename(pdf_path)\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "\n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817eca3-703f-4db7-9947-8f914747a837",
   "metadata": {},
   "source": [
    "The results are really appreciable!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4429ae3d-2ec7-42c7-abe5-04db1068aa92",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da381c-7baa-4713-a92e-df4d654a7024",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d964c-1bbf-4755-a411-2d9624b54a57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Searching Image in PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638405df-bd3e-4490-b85d-706ef7d014db",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52720772-72cb-45b9-a69f-13a88e1add21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD://Cross Search Automation//Previous Cross\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to a folder for saving extracted images\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Find the PDF with an image similar to or exactly the same as the input image\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m exact_match_pdf, most_similar_pdf, similarity \u001b[38;5;241m=\u001b[39m \u001b[43mfind_pdf_with_similar_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_match_pdf:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact match found in PDF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexact_match_pdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 71\u001b[0m, in \u001b[0;36mfind_pdf_with_similar_image\u001b[1;34m(input_image_path, folder_path, image_folder, threshold)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     70\u001b[0m pdf_image_features \u001b[38;5;241m=\u001b[39m extract_image_features(pdf_image)\n\u001b[1;32m---> 71\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m([input_features], [pdf_image_features])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m max_similarity:\n\u001b[0;32m     73\u001b[0m     max_similarity \u001b[38;5;241m=\u001b[39m similarity\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Initialize image model and transform\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "model.eval()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to compute image hash\n",
    "def hash_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        hash_value = hashlib.md5(img.tobytes()).hexdigest()\n",
    "    return hash_value\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# Function to extract images from a PDF and save them\n",
    "def extract_images_from_pdf(pdf_path, image_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_data = base_image[\"image\"]\n",
    "            image_path = os.path.join(image_folder, f\"page_{i}_img_{img_index}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "            image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Function to find the PDF with an image similar to or exactly the same as the input image\n",
    "def find_pdf_with_similar_image(input_image_path, folder_path, image_folder, threshold=0.9):\n",
    "    input_image_hash = hash_image(input_image_path)\n",
    "    input_features = extract_image_features(input_image_path)\n",
    "    \n",
    "    most_similar_pdf = None\n",
    "    max_similarity = -1\n",
    "    exact_match_pdf = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            pdf_images = extract_images_from_pdf(pdf_path, image_folder)\n",
    "\n",
    "            for pdf_image in pdf_images:\n",
    "                pdf_image_hash = hash_image(pdf_image)\n",
    "                if pdf_image_hash == input_image_hash:\n",
    "                    exact_match_pdf = filename\n",
    "                    break\n",
    "\n",
    "                pdf_image_features = extract_image_features(pdf_image)\n",
    "                similarity = cosine_similarity([input_features], [pdf_image_features])[0][0]\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    most_similar_pdf = filename\n",
    "            \n",
    "            if exact_match_pdf:\n",
    "                break\n",
    "    \n",
    "    return exact_match_pdf, most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the image similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your input image and folder containing other PDFs\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Capture.JPG\"  # Replace with the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross\"  # Replace with the path to the folder containing PDFs\n",
    "    image_folder = \"D://Cross Search Automation//Previous Cross\"  # Replace with the path to a folder for saving extracted images\n",
    "\n",
    "    # Find the PDF with an image similar to or exactly the same as the input image\n",
    "    exact_match_pdf, most_similar_pdf, similarity = find_pdf_with_similar_image(input_image_path, folder_path, image_folder)\n",
    "    \n",
    "    if exact_match_pdf:\n",
    "        print(f\"Exact match found in PDF: {exact_match_pdf}\")\n",
    "    else:\n",
    "        print(f\"No exact match found. Most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd543e-0bd9-4da3-9d01-8aba80a47b7e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5aefd-5c4d-4891-b6bf-d3d61a6461f1",
   "metadata": {},
   "source": [
    "RGB error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b5342-2748-42b4-86f3-a14c6fe7129e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0b9c5e-1004-4100-91b8-9c2506e8da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar PDF is: Spec for LED Panel Light with Back-lite[1].pdf with a similarity score of 0.86\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "import hashlib\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Import for cosine similarity\n",
    "\n",
    "# Initialize image model and transform\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "model.eval()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to compute image hash\n",
    "def hash_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        hash_value = hashlib.md5(img.tobytes()).hexdigest()\n",
    "    return hash_value\n",
    "\n",
    "# Function to convert image to RGB if it's not\n",
    "def convert_to_rgb(image):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    return image\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = convert_to_rgb(image)  # Ensure image is in RGB format\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# Function to extract images from a PDF and save them\n",
    "def extract_images_from_pdf(pdf_path, image_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_data = base_image[\"image\"]\n",
    "            image_path = os.path.join(image_folder, f\"page_{i}_img_{img_index}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "            image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Function to find the PDF with an image similar to or exactly the same as the input image\n",
    "def find_pdf_with_similar_image(input_image_path, folder_path, image_folder, threshold=0.9):\n",
    "    input_image_hash = hash_image(input_image_path)\n",
    "    input_features = extract_image_features(input_image_path)\n",
    "    \n",
    "    most_similar_pdf = None\n",
    "    max_similarity = -1\n",
    "    exact_match_pdf = None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            pdf_images = extract_images_from_pdf(pdf_path, image_folder)\n",
    "\n",
    "            for pdf_image in pdf_images:\n",
    "                pdf_image_hash = hash_image(pdf_image)\n",
    "                if pdf_image_hash == input_image_hash:\n",
    "                    exact_match_pdf = filename\n",
    "                    break\n",
    "\n",
    "                pdf_image_features = extract_image_features(pdf_image)\n",
    "                similarity = cosine_similarity([input_features], [pdf_image_features])[0][0]\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    most_similar_pdf = filename\n",
    "            \n",
    "            if exact_match_pdf:\n",
    "                break\n",
    "    \n",
    "    return exact_match_pdf, most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the image similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your input image and folder containing other PDFs\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Capture.JPG\"  # Replace with the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross\"  # Replace with the path to the folder containing PDFs\n",
    "    image_folder = \"D://Cross Search Automation//Previous Cross\"  # Replace with the path to a folder for saving extracted images\n",
    "\n",
    "    # Find the PDF with an image similar to or exactly the same as the input image\n",
    "    exact_match_pdf, most_similar_pdf, similarity = find_pdf_with_similar_image(input_image_path, folder_path, image_folder)\n",
    "    \n",
    "    if exact_match_pdf:\n",
    "        print(f\"Exact match found in PDF: {exact_match_pdf}\")\n",
    "    else:\n",
    "        print(f\"Most similar PDF is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e2502-5198-48d7-a1aa-577bae52cc6c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378863a4-5c1b-4fbe-8d29-d6e33091738f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Now editing to check the image similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c21c6-c60a-42bb-8cda-0b304acdf73b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340b764-b988-4c1f-bf7f-3b756f2838c0",
   "metadata": {},
   "source": [
    "### Test Run 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60601a8b-46a2-42cc-a8c7-5ff9e83c604d",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5559e8b-b20a-411f-afa1-f7d1c8980c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar PDF based on text: mount.pdf with a similarity score of 1.00\n",
      "Most similar PDF based on image: mount.pdf with a similarity score of 0.72\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Initialize image model and transform\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "model.eval()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# Function to extract images from a PDF and save them\n",
    "def extract_images_from_pdf(pdf_path, image_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_data = base_image[\"image\"]\n",
    "            image_path = os.path.join(image_folder, f\"page_{i}_img_{img_index}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "            image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Function to find the most similar PDF based on image similarity\n",
    "def find_most_similar_pdf_image(input_image_path, folder_path, image_folder):\n",
    "    input_features = extract_image_features(input_image_path)\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Extract images from the PDF\n",
    "            pdf_images = extract_images_from_pdf(pdf_path, image_folder)\n",
    "            \n",
    "            for pdf_image in pdf_images:\n",
    "                pdf_image_features = extract_image_features(pdf_image)\n",
    "                similarity = cosine_similarity([input_features], [pdf_image_features])[0][0]\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Function to find the most similar PDF based on text similarity\n",
    "def find_most_similar_pdf_text(input_pdf_path, folder_path):\n",
    "    # Extract text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your input files and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//ol2 mullion mount.pdf\"  # Replace with the path to the input PDF\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Capture.JPG\"  # Replace with the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//Test1\"  # Replace with the path to the folder containing PDFs\n",
    "    image_folder = \"D://Cross Search Automation//Previous Cross//save\"  # Replace with the path to a folder for saving extracted images\n",
    "\n",
    "    # Find the most similar PDF based on text\n",
    "    most_similar_pdf_text, text_similarity = find_most_similar_pdf_text(input_pdf_path, folder_path)\n",
    "    \n",
    "    # Find the most similar PDF based on image\n",
    "    most_similar_pdf_image, image_similarity = find_most_similar_pdf_image(input_image_path, folder_path, image_folder)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Most similar PDF based on text: {most_similar_pdf_text} with a similarity score of {text_similarity:.2f}\")\n",
    "    print(f\"Most similar PDF based on image: {most_similar_pdf_image} with a similarity score of {image_similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ffbce-36d2-4ea4-9d90-706109226e65",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f7480-3058-45ae-ace5-2b5c8ca5d361",
   "metadata": {},
   "source": [
    "### Test Run 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763983c4-0a65-4b65-b094-2805a76ffc05",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e846503-d572-4602-b15d-d44fe7454d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar PDF based on text: Egress.pdf with a similarity score of 1.00\n",
      "Most similar PDF based on image: Egress.pdf with a similarity score of 0.95\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Initialize image model and transform\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # Use specific weights or ResNet50_Weights.DEFAULT for the latest\n",
    "model = resnet50(weights=weights).to(device)\n",
    "model.eval()\n",
    "preprocess = weights.transforms()  # Use the recommended transforms for the weights\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# Function to extract images from a PDF and save them\n",
    "def extract_images_from_pdf(pdf_path, image_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_data = base_image[\"image\"]\n",
    "            image_path = os.path.join(image_folder, f\"page_{i}_img_{img_index}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "            image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Function to find the most similar PDF based on image similarity\n",
    "def find_most_similar_pdf_image(input_image_path, folder_path, image_folder):\n",
    "    input_features = extract_image_features(input_image_path)\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Extract images from the PDF\n",
    "            pdf_images = extract_images_from_pdf(pdf_path, image_folder)\n",
    "            \n",
    "            for pdf_image in pdf_images:\n",
    "                pdf_image_features = extract_image_features(pdf_image)\n",
    "                similarity = cosine_similarity([input_features], [pdf_image_features])[0][0]\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Function to find the most similar PDF based on text similarity\n",
    "def find_most_similar_pdf_text(input_pdf_path, folder_path):\n",
    "    # Extract text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your input files and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Linear Emergency Egress Light 1.pdf\"  # Replace with the path to the input PDF\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Capture2.JPG\"  # Replace with the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//Test1\"  # Replace with the path to the folder containing PDFs\n",
    "    image_folder = \"D://Cross Search Automation//Previous Cross//save\"  # Replace with the path to a folder for saving extracted images\n",
    "\n",
    "    # Find the most similar PDF based on text\n",
    "    most_similar_pdf_text, text_similarity = find_most_similar_pdf_text(input_pdf_path, folder_path)\n",
    "    \n",
    "    # Find the most similar PDF based on image\n",
    "    most_similar_pdf_image, image_similarity = find_most_similar_pdf_image(input_image_path, folder_path, image_folder)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Most similar PDF based on text: {most_similar_pdf_text} with a similarity score of {text_similarity:.2f}\")\n",
    "    print(f\"Most similar PDF based on image: {most_similar_pdf_image} with a similarity score of {image_similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ca98f-9d7c-46c7-a57f-9e4d2217e8bf",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bd863-0660-48b3-b7d1-a6df2baf9d11",
   "metadata": {},
   "source": [
    "### Test 3 with a slight change in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6cd44-6865-4d4f-93c1-76120b1786a3",
   "metadata": {},
   "source": [
    "Adding the following:\n",
    "\n",
    "1. Ensured Correct Image Processing: The extract_image_features function now converts images to RGB format to ensure they are correctly processed.\n",
    "2. Normalized Image Features: Feature vectors are normalized before comparison to provide more accurate similarity measurements.\n",
    "3. Accurate Feature Comparison: The code compares all images extracted from each PDF to find the most similar one.\n",
    "4. Improved Consistency in Preprocessing: The preprocessing function is now more consistent and uses recommended transforms for the pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cacb6-f43c-4d0a-a73f-9fc8c4593dbe",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef07cbfd-400d-4609-aa16-be4a5746e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar PDF based on text: mount.pdf with a similarity score of 1.00\n",
      "Most similar PDF based on image: Egress.pdf with a similarity score of 0.73\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Initialize image model and transform\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # Use specific weights or ResNet50_Weights.DEFAULT for the latest\n",
    "model = resnet50(weights=weights).to(device)\n",
    "model.eval()\n",
    "preprocess = weights.transforms()  # Use the recommended transforms for the weights\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to extract and normalize image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB format\n",
    "    image = preprocess(image).unsqueeze(0).to(device)  # Apply preprocessing transform\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    features = features.cpu().numpy().flatten()\n",
    "    normalized_features = normalize([features])[0]  # Normalize the features\n",
    "    return normalized_features\n",
    "\n",
    "# Function to extract images from a PDF and save them\n",
    "def extract_images_from_pdf(pdf_path, image_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_data = base_image[\"image\"]\n",
    "            image_path = os.path.join(image_folder, f\"page_{i}_img_{img_index}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_data)\n",
    "            image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Function to find the most similar PDF based on image similarity\n",
    "def find_most_similar_pdf_image(input_image_path, folder_path, image_folder):\n",
    "    input_features = extract_image_features(input_image_path)\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Extract images from the PDF\n",
    "            pdf_images = extract_images_from_pdf(pdf_path, image_folder)\n",
    "            \n",
    "            for pdf_image in pdf_images:\n",
    "                pdf_image_features = extract_image_features(pdf_image)\n",
    "                similarity = cosine_similarity([input_features], [pdf_image_features])[0][0]\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Function to find the most similar PDF based on text similarity\n",
    "def find_most_similar_pdf_text(input_pdf_path, folder_path):\n",
    "    # Extract text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your input files and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//ol2 mullion mount.pdf\"  # Replace with the path to the input PDF\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Capture.JPG\"  # Replace with the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//Test1\"  # Replace with the path to the folder containing PDFs\n",
    "    image_folder = \"D://Cross Search Automation//Previous Cross//save\"  # Replace with the path to a folder for saving extracted images\n",
    "\n",
    "    # Find the most similar PDF based on text\n",
    "    most_similar_pdf_text, text_similarity = find_most_similar_pdf_text(input_pdf_path, folder_path)\n",
    "    \n",
    "    # Find the most similar PDF based on image\n",
    "    most_similar_pdf_image, image_similarity = find_most_similar_pdf_image(input_image_path, folder_path, image_folder)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Most similar PDF based on text: {most_similar_pdf_text} with a similarity score of {text_similarity:.2f}\")\n",
    "    print(f\"Most similar PDF based on image: {most_similar_pdf_image} with a similarity score of {image_similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bfb42-6912-41ac-9718-231197834e98",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860ffc9-15d9-4ddc-aad8-cbc8fc1980ec",
   "metadata": {},
   "source": [
    "### The results of the most similar PDF search based on image is not accurate, so we will try and run the code for that functionality separately and then try and integrate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948389a-498f-4193-8b39-3199f605b44c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c64285-0479-4622-bd90-3b08191d294e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backbone 2: Most similar PDF search based on image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604dc28-0b88-4640-91bf-2fdaaeee3870",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0eda25e-136f-4660-8068-6b2abe891c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            images.append(np.array(image))\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def calculate_image_similarity(img1, img2):\n",
    "    \"\"\"Calculates the similarity between two images using histogram comparison.\"\"\"\n",
    "    # Convert images to BGR format if they are not already\n",
    "    if len(img1.shape) == 2:  # Grayscale image\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    if len(img2.shape) == 2:  # Grayscale image\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    # Convert to grayscale for histogram comparison\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate histogram and similarity\n",
    "    hist1 = cv2.calcHist([img1_gray], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([img2_gray], [0], None, [256], [0, 256])\n",
    "    \n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                similarity = calculate_image_similarity(input_image, img)\n",
    "\n",
    "                if similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba3504-e983-4323-a22b-5b77f09e637c",
   "metadata": {},
   "source": [
    "But this result is faulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecf57cd5-f4bf-4821-97b2-cf702aeb4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: T8_Tube_Type_C_PS.pdf with a similarity score of: 0.71\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    \n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "                if similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282476d-e7a4-44b6-a5c6-b2b52c8b6200",
   "metadata": {},
   "source": [
    "The result needs to be more accurate. Testing with multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00dbb73f-199f-42d3-890b-16c842a8e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For image 'D://Cross Search Automation//Previous Cross//Vendor Lights//test.png', the most similar PDF is: 'T8_Tube_Type_C_PS.pdf' with a similarity score of: 0.71\n",
      "For image 'D://Cross Search Automation//Previous Cross//Vendor Lights//test2.jpg', the most similar PDF is: 'Coloris_RGBW_ELPL_PS.pdf' with a similarity score of: 0.84\n",
      "For image 'D://Cross Search Automation//Previous Cross//Vendor Lights//test4.png', the most similar PDF is: 'Delphi_Mini_WP_PS.pdf' with a similarity score of: 0.79\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def find_most_similar_pdfs(input_image_paths, folder_path):\n",
    "    \"\"\"Finds the most similar PDFs for multiple input images.\"\"\"\n",
    "    results = {}  # Dictionary to store results for each input image\n",
    "\n",
    "    for input_image_path in input_image_paths:\n",
    "        input_image = Image.open(input_image_path)\n",
    "        \n",
    "        # Convert input image to RGB if necessary\n",
    "        if input_image.mode != 'RGB':\n",
    "            input_image = input_image.convert('RGB')\n",
    "\n",
    "        input_image_features = extract_image_features(input_image)\n",
    "        \n",
    "        most_similar_pdf = None\n",
    "        highest_similarity = -1\n",
    "\n",
    "        for pdf_file in os.listdir(folder_path):\n",
    "            if pdf_file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(folder_path, pdf_file)\n",
    "                extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "                for img in extracted_images:\n",
    "                    img_features = extract_image_features(img)\n",
    "                    similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "                    if similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        most_similar_pdf = pdf_file\n",
    "\n",
    "        # Store the result for the current input image\n",
    "        results[input_image_path] = (most_similar_pdf, highest_similarity)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Usage example\n",
    "input_image_paths = [\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\",  # Provide paths to the input images\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test2.jpg\",\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test4.png\",\n",
    "]\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "similar_pdfs = find_most_similar_pdfs(input_image_paths, folder_path)\n",
    "\n",
    "# Print the results\n",
    "for image_path, (pdf, score) in similar_pdfs.items():\n",
    "    if pdf:\n",
    "        print(f\"For image '{image_path}', the most similar PDF is: '{pdf}' with a similarity score of: {score:.2f}\")\n",
    "    else:\n",
    "        print(f\"No similar images found in the PDFs for image '{image_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469c5e3-c4f9-45e9-b393-fa935b73e379",
   "metadata": {},
   "source": [
    "The code still is not able to accurately get all the images right. THE BASE MAIN CODE FOR NOW IS THIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d77d8c1-af71-49e2-86af-227ff376528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: T8_Tube_Type_C_PS.pdf with a similarity score of: 0.72\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import ORB, match_descriptors, BRIEF\n",
    "from skimage.transform import integral_image\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using ORB.\"\"\"\n",
    "    orb = ORB(n_keypoints=1000)\n",
    "    image1_gray = rgb2gray(np.array(image1))\n",
    "    image2_gray = rgb2gray(np.array(image2))\n",
    "    \n",
    "    orb.detect_and_extract(image1_gray)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "    \n",
    "    orb.detect_and_extract(image2_gray)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "    \n",
    "    matches = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
    "    return len(matches)\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "    best_match_count = 0\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches\n",
    "                combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84634c5-9857-4d51-beb9-4bc5f1261c5b",
   "metadata": {},
   "source": [
    "The results look a little more better. Considering this to be the final code for the backbone 2. Now we try again for multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d03e1ba7-eb7b-4a36-a9d9-e3441d0d5013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input image D://Cross Search Automation//Previous Cross//Vendor Lights//test.png, the most similar PDF is: T8_Tube_Type_C_PS.pdf with a similarity score of: 0.72\n",
      "For input image D://Cross Search Automation//Previous Cross//Vendor Lights//test2.jpg, the most similar PDF is: Coloris_RGBW_ELPL_PS.pdf with a similarity score of: 0.85\n",
      "For input image D://Cross Search Automation//Previous Cross//Vendor Lights//test4.png, the most similar PDF is: Delphi_Mini_WP_PS.pdf with a similarity score of: 0.89\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import ORB, match_descriptors\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using ORB.\"\"\"\n",
    "    orb = ORB(n_keypoints=1000)\n",
    "    image1_gray = rgb2gray(np.array(image1))\n",
    "    image2_gray = rgb2gray(np.array(image2))\n",
    "    \n",
    "    orb.detect_and_extract(image1_gray)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "    \n",
    "    orb.detect_and_extract(image2_gray)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "    \n",
    "    matches = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
    "    return len(matches)\n",
    "\n",
    "def find_most_similar_pdfs(input_image_paths, folder_path):\n",
    "    \"\"\"Finds the most similar PDF for each input image.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for input_image_path in input_image_paths:\n",
    "        input_image = Image.open(input_image_path)\n",
    "        \n",
    "        # Convert input image to RGB if necessary\n",
    "        if input_image.mode != 'RGB':\n",
    "            input_image = input_image.convert('RGB')\n",
    "\n",
    "        input_image_features = extract_image_features(input_image)\n",
    "        most_similar_pdf = None\n",
    "        highest_similarity = -1\n",
    "\n",
    "        for pdf_file in os.listdir(folder_path):\n",
    "            if pdf_file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(folder_path, pdf_file)\n",
    "                extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "                for img in extracted_images:\n",
    "                    img_features = extract_image_features(img)\n",
    "                    similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                    keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                    # Combine similarity and keypoint matches\n",
    "                    combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                    if combined_score > highest_similarity:\n",
    "                        highest_similarity = combined_score\n",
    "                        most_similar_pdf = pdf_file\n",
    "\n",
    "        results[input_image_path] = (most_similar_pdf, highest_similarity)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Usage example\n",
    "input_image_paths = [\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\",\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test2.jpg\",\n",
    "    \"D://Cross Search Automation//Previous Cross//Vendor Lights//test4.png\",\n",
    "    # Add more image paths here\n",
    "]\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "results = find_most_similar_pdfs(input_image_paths, folder_path)\n",
    "\n",
    "for input_image_path, (most_similar_pdf, similarity_score) in results.items():\n",
    "    if most_similar_pdf:\n",
    "        print(f\"For input image {input_image_path}, the most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "    else:\n",
    "        print(f\"For input image {input_image_path}, no similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d252b-84ca-455f-9268-f15b786c93e4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d0982-a602-4703-ba60-22c3640e6103",
   "metadata": {},
   "source": [
    "The Database has increased and the error of ORB persists.... handling it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f74bd1-b66b-4e21-a94b-9e9a6c69b5e4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c317ec6-f970-4463-8563-814e0d204be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Simplex_LLB_4'_40W_4000K_100-277 V_TDS.pdf with a similarity score of: 0.86\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for SIFT.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using SIFT.\"\"\"\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                \n",
    "                # Use keypoint matching with SIFT\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches\n",
    "                combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8710a5-b441-4a67-b6d3-183e6540ec63",
   "metadata": {},
   "source": [
    "Now this is what I call accuracy and the code for the Backbone 2!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fbaa3-0d98-4d6c-aa6d-990d62d68a56",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aabe33-9d9f-4398-8203-c0b5eec28b2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Most similar PDF based on text and image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f1c52-7386-4846-803e-bf0c581c494c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e7423c-70e6-41dc-bbea-312b996d3222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF based on text is: Delphi_FPCL_PS.pdf with a similarity score of 0.30\n",
      "The most similar PDF based on image is: Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to find the most similar PDF based on text\n",
    "def find_most_similar_pdf_text(input_pdf_path, folder_path):\n",
    "    # Extract text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "\n",
    "    # Initialize variables to track the most similar PDF\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "\n",
    "    # Iterate over each PDF in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            # Extract text from the current PDF\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            # Compute similarity\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "            # Update most similar PDF if needed\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "# Function to extract images from a PDF file\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            images.append(np.array(image))\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "# Function to calculate the similarity between two images using histogram comparison\n",
    "def calculate_image_similarity(img1, img2):\n",
    "    # Convert images to BGR format if they are not already\n",
    "    if len(img1.shape) == 2:  # Grayscale image\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    if len(img2.shape) == 2:  # Grayscale image\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    # Convert to grayscale for histogram comparison\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate histogram and similarity\n",
    "    hist1 = cv2.calcHist([img1_gray], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([img2_gray], [0], None, [256], [0, 256])\n",
    "    \n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "# Function to find the most similar PDF based on an image\n",
    "def find_most_similar_pdf_image(input_image_path, folder_path):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                similarity = calculate_image_similarity(input_image, img)\n",
    "\n",
    "                if similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Main function to handle both text-based and image-based PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to the input PDF/image and the folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"  # Provide the path to the input image\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF based on text\n",
    "    most_similar_pdf_text, similarity_text = find_most_similar_pdf_text(input_pdf_path, folder_path)\n",
    "    \n",
    "    if most_similar_pdf_text:\n",
    "        print(f\"The most similar PDF based on text is: {most_similar_pdf_text} with a similarity score of {similarity_text:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found based on text.\")\n",
    "\n",
    "    # Find the most similar PDF based on image\n",
    "    most_similar_pdf_image, similarity_image = find_most_similar_pdf_image(input_image_path, folder_path)\n",
    "\n",
    "    if most_similar_pdf_image:\n",
    "        print(f\"The most similar PDF based on image is: {most_similar_pdf_image} with a similarity score of: {similarity_image:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fe4490-e91b-4bc3-b953-15732fa9fa71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar PDFs based on text:\n",
      "Coloris_RGBW_ELPL_PS.pdf with a similarity score of 0.26\n",
      "Delphi_BLPL_PS.pdf with a similarity score of 0.25\n",
      "Delphi_FPCL_PS.pdf with a similarity score of 0.30\n",
      "Delphi_Mini_WP_PS.pdf with a similarity score of 0.28\n",
      "ol2 mullion mount.pdf with a similarity score of 0.22\n",
      "Orwin_DL_PS.pdf with a similarity score of 0.23\n",
      "Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of 0.30\n",
      "T8_Tube_Type_C_PS.pdf with a similarity score of 0.26\n",
      "\n",
      "Similar PDFs based on image:\n",
      "Coloris_RGBW_ELPL_PS.pdf with a similarity score of 0.77\n",
      "Delphi_BLPL_PS.pdf with a similarity score of 0.97\n",
      "Delphi_FPCL_PS.pdf with a similarity score of 0.71\n",
      "Delphi_Mini_WP_PS.pdf with a similarity score of 0.99\n",
      "Orwin_DL_PS.pdf with a similarity score of 1.00\n",
      "Sigma_EMTUBE_TypeB_PS.pdf with a similarity score of 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text (example: remove extra spaces and newlines)\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Function to compare two texts and return similarity using cosine similarity\n",
    "def compare_texts(text1, text2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Function to find all similar PDFs based on text\n",
    "def find_similar_pdfs_text(input_pdf_path, folder_path, similarity_threshold=0.1):\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    similar_pdfs = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            similarity = compare_texts(input_text, folder_pdf_text)\n",
    "\n",
    "            if similarity >= similarity_threshold:\n",
    "                similar_pdfs.append((filename, similarity))\n",
    "\n",
    "    return similar_pdfs\n",
    "\n",
    "# Function to extract images from a PDF file\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            images.append(np.array(image))\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "# Function to calculate the similarity between two images using histogram comparison\n",
    "def calculate_image_similarity(img1, img2):\n",
    "    if len(img1.shape) == 2:  # Grayscale image\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    if len(img2.shape) == 2:  # Grayscale image\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    hist1 = cv2.calcHist([img1_gray], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([img2_gray], [0], None, [256], [0, 256])\n",
    "\n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "# Function to find all similar PDFs based on an image\n",
    "def find_similar_pdfs_image(input_image_path, folder_path, similarity_threshold=0.1):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    similar_pdfs = []\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                similarity = calculate_image_similarity(input_image, img)\n",
    "\n",
    "                if similarity >= similarity_threshold:\n",
    "                    similar_pdfs.append((pdf_file, similarity))\n",
    "                    break  # Break to avoid duplicate entries for the same PDF\n",
    "\n",
    "    return similar_pdfs\n",
    "\n",
    "# Main function to handle both text-based and image-based PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "    similarity_threshold = 0.1  # Adjust this threshold as needed\n",
    "\n",
    "    # Find all similar PDFs based on text\n",
    "    similar_pdfs_text = find_similar_pdfs_text(input_pdf_path, folder_path, similarity_threshold)\n",
    "    if similar_pdfs_text:\n",
    "        print(\"Similar PDFs based on text:\")\n",
    "        for pdf, score in similar_pdfs_text:\n",
    "            print(f\"{pdf} with a similarity score of {score:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDFs found based on text.\")\n",
    "\n",
    "    # Find all similar PDFs based on image\n",
    "    similar_pdfs_image = find_similar_pdfs_image(input_image_path, folder_path, similarity_threshold)\n",
    "    if similar_pdfs_image:\n",
    "        print(\"\\nSimilar PDFs based on image:\")\n",
    "        for pdf, score in similar_pdfs_image:\n",
    "            print(f\"{pdf} with a similarity score of {score:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDFs found based on image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588e953-8b60-447f-8d4d-1da28fa08d35",
   "metadata": {},
   "source": [
    "Lets apply the changes and updated codes in Backbone 1 and Backbone 2 combined to give the desired changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e950a003-1145-43cf-a5bc-0ddd64484253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF on the basis of Image is: Coloris_RGBW_ELPL_PS.pdf with a similarity score of: 0.85\n",
      "The most similar PDF on the basis of Text is: Delphi_FPCL_PS.pdf with a similarity score of 0.90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import ORB, match_descriptors\n",
    "from skimage.color import rgb2gray\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "# Initialize the BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using ORB.\"\"\"\n",
    "    orb = ORB(n_keypoints=1000)\n",
    "    image1_gray = rgb2gray(np.array(image1))\n",
    "    image2_gray = rgb2gray(np.array(image2))\n",
    "    \n",
    "    orb.detect_and_extract(image1_gray)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "    \n",
    "    orb.detect_and_extract(image2_gray)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "    \n",
    "    matches = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
    "    return len(matches)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text by removing extra spaces and newlines.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"Encodes text using BERT model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # Use the [CLS] token's embedding as the sentence representation\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "def find_most_similar_pdf(input_path, folder_path, use_text=False):\n",
    "    \"\"\"Finds the PDF with the most similar image or text to the input.\"\"\"\n",
    "    if use_text:\n",
    "        # Extract and preprocess text from the input PDF\n",
    "        input_text = preprocess_text(extract_text_from_pdf(input_path))\n",
    "        input_embedding = encode_text(input_text)\n",
    "        \n",
    "        # Initialize variables to track the most similar PDF\n",
    "        max_similarity = -1\n",
    "        most_similar_pdf = None\n",
    "\n",
    "        # Preprocess all PDFs in the folder and batch encode\n",
    "        pdf_embeddings = {}\n",
    "        pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "        \n",
    "        for filename in pdf_files:\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "            pdf_embeddings[filename] = encode_text(folder_pdf_text)\n",
    "\n",
    "        # Compute cosine similarity for each PDF against the input PDF\n",
    "        for filename, folder_pdf_embedding in pdf_embeddings.items():\n",
    "            similarity = cosine_similarity(input_embedding, folder_pdf_embedding).item()\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pdf = filename\n",
    "\n",
    "    else:\n",
    "        # For image similarity\n",
    "        input_image = Image.open(input_path)\n",
    "        \n",
    "        # Convert input image to RGB if necessary\n",
    "        if input_image.mode != 'RGB':\n",
    "            input_image = input_image.convert('RGB')\n",
    "\n",
    "        input_image_features = extract_image_features(input_image)\n",
    "        most_similar_pdf = None\n",
    "        highest_similarity = -1\n",
    "        best_match_count = 0\n",
    "\n",
    "        for pdf_file in os.listdir(folder_path):\n",
    "            if pdf_file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(folder_path, pdf_file)\n",
    "                extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "                for img in extracted_images:\n",
    "                    img_features = extract_image_features(img)\n",
    "                    similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                    keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                    # Combine similarity and keypoint matches\n",
    "                    combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                    if combined_score > highest_similarity:\n",
    "                        highest_similarity = combined_score\n",
    "                        most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, max_similarity if use_text else highest_similarity\n",
    "\n",
    "# Usage example for image similarity\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test2.jpg\"\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path, use_text=False)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF on the basis of Image is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")\n",
    "\n",
    "# Usage example for text similarity\n",
    "input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//configurable-cpx.pdf\"\n",
    "\n",
    "most_similar_pdf, similarity = find_most_similar_pdf(input_pdf_path, folder_path, use_text=True)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF on the basis of Text is: {most_similar_pdf} with a similarity score of {similarity:.2f}\")\n",
    "else:\n",
    "    print(\"No similar PDFs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a2e3c-e190-4ea7-a604-a21172fa7833",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53d8fc-1ee9-4fe6-8d04-3b174a2c12eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb848a-e0cc-4fd5-9fa1-27ac8fa8cf03",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cca8bf-58a9-48c0-9c98-c30cb2295fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ORB found no features. Try passing in an image containing greater intensity contrasts between adjacent pixels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 219\u001b[0m\n\u001b[0;32m    216\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD://Cross Search Automation//Previous Cross//IKIO Lights\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Find the most similar PDF by image\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m most_similar_pdf_image, image_similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mfind_most_similar_pdf_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m most_similar_pdf_image:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe most similar PDF by image is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_similar_pdf_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with a similarity score of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_similarity_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 178\u001b[0m, in \u001b[0;36mfind_most_similar_pdf_image\u001b[1;34m(input_image_path, folder_path)\u001b[0m\n\u001b[0;32m    176\u001b[0m img_features \u001b[38;5;241m=\u001b[39m extract_image_features(img)\n\u001b[0;32m    177\u001b[0m similarity \u001b[38;5;241m=\u001b[39m calculate_image_similarity(input_image_features, img_features)\n\u001b[1;32m--> 178\u001b[0m keypoint_match_count \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Combine similarity and keypoint matches\u001b[39;00m\n\u001b[0;32m    181\u001b[0m combined_score \u001b[38;5;241m=\u001b[39m similarity \u001b[38;5;241m+\u001b[39m (keypoint_match_count \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Normalize keypoint matches\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m, in \u001b[0;36mmatch_keypoints\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m     90\u001b[0m keypoints1 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mkeypoints\n\u001b[0;32m     91\u001b[0m descriptors1 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mdescriptors\n\u001b[1;32m---> 93\u001b[0m \u001b[43morb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage2_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m keypoints2 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mkeypoints\n\u001b[0;32m     95\u001b[0m descriptors2 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mdescriptors\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skimage\\feature\\orb.py:342\u001b[0m, in \u001b[0;36mORB.detect_and_extract\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    339\u001b[0m     descriptors_list\u001b[38;5;241m.\u001b[39mappend(descriptors)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scales_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORB found no features. Try passing in an image containing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreater intensity contrasts between adjacent pixels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    347\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(keypoints_list)\n\u001b[0;32m    348\u001b[0m responses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(responses_list)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ORB found no features. Try passing in an image containing greater intensity contrasts between adjacent pixels."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import nltk\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import ORB, match_descriptors\n",
    "from skimage.color import rgb2gray\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize ResNet model with updated weights argument\n",
    "resnet_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Initialize the Sentence-BERT model once at the start\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using ORB.\"\"\"\n",
    "    orb = ORB(n_keypoints=1000)\n",
    "    image1_gray = rgb2gray(np.array(image1))\n",
    "    image2_gray = rgb2gray(np.array(image2))\n",
    "    \n",
    "    orb.detect_and_extract(image1_gray)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "    \n",
    "    orb.detect_and_extract(image2_gray)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "    \n",
    "    matches = match_descriptors(descriptors1, descriptors2, cross_check=True)\n",
    "    return len(matches)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text for NLP processing.\"\"\"\n",
    "    # Remove punctuation, convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(text) if word not in nltk.corpus.stopwords.words('english')]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    \n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "def generate_ngrams(text, n=2):\n",
    "    \"\"\"Generates n-grams from text.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "def compute_embedding(text):\n",
    "    \"\"\"Computes embeddings for a given text using Sentence-BERT.\"\"\"\n",
    "    # Split text into smaller chunks for more granular embeddings\n",
    "    sentences = text.split('. ')\n",
    "    embeddings = sentence_model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    \"\"\"Computes similarity score between two sets of embeddings.\"\"\"\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.max().item()\n",
    "\n",
    "def process_pdf(file_info):\n",
    "    \"\"\"Processes a single PDF file and calculates its similarity score.\"\"\"\n",
    "    input_embedding, input_pdf_path, pdf_path = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(folder_pdf_text, 2)\n",
    "    enriched_text = ' '.join([folder_pdf_text] + bigrams)\n",
    "    \n",
    "    folder_pdf_embedding = compute_embedding(enriched_text)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    similarity = compute_similarity(input_embedding, folder_pdf_embedding)\n",
    "    return (pdf_path, similarity)\n",
    "\n",
    "def find_most_similar_pdf_image(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "    best_match_count = 0\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches\n",
    "                combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "def find_most_similar_pdf_text(input_pdf_path, folder_path):\n",
    "    \"\"\"Finds the most similar PDF in a folder using Sentence-BERT embeddings.\"\"\"\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(input_text, 2)\n",
    "    enriched_text = ' '.join([input_text] + bigrams)\n",
    "    \n",
    "    input_embedding = compute_embedding(enriched_text)\n",
    "\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_pdf, [(input_embedding, input_pdf_path, pdf_path) for pdf_path in pdf_files])\n",
    "\n",
    "    for pdf_path, similarity in results:\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = os.path.basename(pdf_path)\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths for input files and folders\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test3.jpg\"\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//configurable-cpx.pdf\"\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "\n",
    "    # Find the most similar PDF by image\n",
    "    most_similar_pdf_image, image_similarity_score = find_most_similar_pdf_image(input_image_path, folder_path)\n",
    "    if most_similar_pdf_image:\n",
    "        print(f\"The most similar PDF by image is: {most_similar_pdf_image} with a similarity score of: {image_similarity_score:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar images found in the PDFs.\")\n",
    "\n",
    "    # Find the most similar PDF by text\n",
    "    most_similar_pdf_text, text_similarity_score = find_most_similar_pdf_text(input_pdf_path, folder_path)\n",
    "    if most_similar_pdf_text:\n",
    "        print(f\"The most similar PDF by text is: {most_similar_pdf_text} with a similarity score of {text_similarity_score:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found by text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940dd5d9-e9b4-4d6e-9d5b-58f663eb7192",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d20102-be17-447a-8b3a-0287a41859fc",
   "metadata": {},
   "source": [
    "The image program is not performing well due to increase in the database of the our light's pdf's. Therefore, certain changes in the contract enhancements and AI models were elaborately hindered with to get the following code vwith corresponding results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94da9d-1791-4824-9056-29db7b06bf7d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9f59b3-32df-435d-97ff-b1af606b17f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF by text is: T8_Tube_Type_C_PS.pdf with a similarity score of 0.82\n",
      "The most similar PDF by image is: Simplex_LLB_4'_40W_4000K_100-277 V_TDS.pdf with a similarity score of 0.86\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize Sentence-BERT model and other required objects\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "### Text Processing Functions ###\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text by removing punctuation, lowercasing, and lemmatizing.\"\"\"\n",
    "    # Remove punctuation, convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    \n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "def generate_ngrams(text, n=2):\n",
    "    \"\"\"Generates n-grams from text.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "def compute_embedding(text):\n",
    "    \"\"\"Computes the embeddings of text using Sentence-BERT.\"\"\"\n",
    "    # Split text into smaller chunks for more granular embeddings\n",
    "    sentences = text.split('. ')\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    \"\"\"Computes the similarity score between two sets of embeddings.\"\"\"\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.max().item()  # Use max similarity across chunks\n",
    "\n",
    "def process_pdf(file_info):\n",
    "    \"\"\"Processes a single PDF file and calculates its similarity score.\"\"\"\n",
    "    input_embedding, input_pdf_path, pdf_path = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(folder_pdf_text, 2)\n",
    "    enriched_text = ' '.join([folder_pdf_text] + bigrams)  # Concatenate original text with bigrams\n",
    "    \n",
    "    folder_pdf_embedding = compute_embedding(enriched_text)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    similarity = compute_similarity(input_embedding, folder_pdf_embedding)\n",
    "    return (pdf_path, similarity)\n",
    "\n",
    "### Image Processing Functions ###\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for SIFT.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using SIFT.\"\"\"\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "### Usage Examples ###\n",
    "\n",
    "def find_most_similar_pdf_by_text(input_pdf_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar text content to the input PDF using Sentence-BERT embeddings.\"\"\"\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Enrich text with bigrams\n",
    "    bigrams = generate_ngrams(input_text, 2)\n",
    "    enriched_text = ' '.join([input_text] + bigrams)  # Concatenate original text with bigrams\n",
    "    \n",
    "    input_embedding = compute_embedding(enriched_text)\n",
    "\n",
    "    # List all PDF files in the folder\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_pdf, [(input_embedding, input_pdf_path, pdf_path) for pdf_path in pdf_files])\n",
    "\n",
    "    # Process results to find the most similar PDF\n",
    "    for pdf_path, similarity in results:\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = os.path.basename(pdf_path)\n",
    "\n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "def find_most_similar_pdf_by_image(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                \n",
    "                # Use keypoint matching with SIFT\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches\n",
    "                combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Main function to demonstrate usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths for the input PDF, input image, and the folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"\n",
    "    input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test.png\"\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "\n",
    "    # Find the most similar PDF by text content\n",
    "    most_similar_pdf_text, similarity_text = find_most_similar_pdf_by_text(input_pdf_path, folder_path)\n",
    "    if most_similar_pdf_text:\n",
    "        print(f\"The most similar PDF by text is: {most_similar_pdf_text} with a similarity score of {similarity_text:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar PDF found by text.\")\n",
    "\n",
    "    # Find the most similar PDF by image content\n",
    "    most_similar_pdf_image, similarity_image = find_most_similar_pdf_by_image(input_image_path, folder_path)\n",
    "    if most_similar_pdf_image:\n",
    "        print(f\"The most similar PDF by image is: {most_similar_pdf_image} with a similarity score of {similarity_image:.2f}\")\n",
    "    else:\n",
    "        print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ca4e8-fd3d-4479-b144-386bade3aaa7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7368054-7e8f-4f3b-a80b-194c2411f7d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extracting details of the similarities of the final pdf search through text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efeec3-1b11-4aa7-b271-970ab1c94755",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b24a2e9-1ab1-41a7-a282-e15804fb33f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: T8_Tube_Type_C_PS.pdf with an average similarity score of 0.82\n",
      "\n",
      "Top 5 most similar sentences or details:\n",
      "Score: 0.82\n",
      "Input PDF sentence: lbk lightbar kit led retrofit lbk commercial indoor lbk configurable catalog number note type feature specification intended use lbk kit provides simple costeffective integrated led solution retrofit nearly fluorescent fixture t8 t12 t5 lamp lightbar kit provide reliability thermal performance longevity integrated led system simplicity installing fluorescent lamp used existing fluorescent lampholders ballast used operation greatly increasing reliability construction optic rigid formed steel channel highperformance led board mounted directly optimal thermal performance diffuse acrylic lens increase uniformity control brightness lbk available standard 4 2 3 configuration increased flexibility linear application electrical longlife led coupled highefficiency driver provide extended service life lbk rated deliver greater l80 performance 60000 hour calculated l70 140000 hr led high efficiency lightbar kit performance level exceeding 150 lpw installation magnet secure lightbar easy positioning alignment selftapping tek screw included secure bar final installation driver mounted existing ballast channel lightbars driver plug modular wiring harness configuration specified ordering installation simplicity listing ulcul classified damp location tested lm80 standard north america standard taa compliance baa compliant product available consult factory designlights consortium dlc qualified product version product dlc qualified check dlc qualified product list wwwdesignlightsorgqpl confirm version qualified government procurement baa product baa option qualifies domestic end product buy american act implemented far dfars product baa option qualifies manufactured united state dot buy america regulation baba build america buy america product baa option qualifies produced united state definition build america buy america act refer wwwacuitybrandscombuyamerican additional information warranty fiveyear warranty coverage luminaires includes fixture construction led light engine driver term condition apply warranty provided statement specification sheet create warranty kind express implied warranty disclaimed extended warranty available certain application note actual performance differ result enduser environment application value design typical value measured laboratory condition 25 c specification subject change notice specification length 4625 3440 2263 width 161 height 09 lbk performance 1600lmhe 2000lmhe 3000lmhe 4000lmhe 6000lmhe 8000lmhe 12000lmhe 10w 13w 20w 26w 39w 51w 77w 2 ft 2ft 1 bar 40k 1475 lm 1995 lm 99 w 133 w 149 lpw 150 lpw 2ft 2 bar 40k 1485 lm 2005 lm 3045 lm 3908 lm 99 w 133 w 200 w 251 w 150 lpw 151 lpw 152 lpw 155 lpw 2ft 3 bar 40k 1985 lm 3009 lm 3891 lm 5703 lm 132 w 197 w 247 w 374 w 151 lpw 153 lpw 158 lpw 152 lpw 2ft 4 bar 40k 5663 lm 7708 lm 375 w 505 w 151 lpw 153 lpw 3 ft 3ft 1 bar 40k 1463 lm 1990 lm 3000 lm 3970 lm 99 w 133 w 200 w 251 w 147 lpw 150 lpw 150 lpw 158 lpw 3ft 2 bar 40k 2000 lm 3087 lm 4000 lm 5650 lm 132 w 197 w 251 w 374 w 152 lpw 157 lpw 159 lpw 151 lpw 4 ft 4ft 1 bar 40k 1564 lm 2022 lm 3057 lm 3938 lm 5775 lm 99 w 132 w 199w 249 w 375 w 158 lpw 153 lpw 154 lpw 158 lpw 154 lpw 4ft 2 bar 40k 2061 lm 3149 lm 4097 lm 6007 lm 7903 lm 131 w 196 w 245 w 372 w 503 w 158 lpw 161 lpw 167 lpw 162 lpw 157 lpw 4ft 3 bar 40k 3151 lm 4044 lm 6025 lm 7925 lm 195 w 243 w 367 w 505 w 162 lpw 166 lpw 164 lpw 157 lpw 4ft 4 bar 40k 4050 lm 6050 lm 8140 lm 11979 lm 250 w 367 w 494 w 749 w 162 lpw 165 lpw 165 lpw 160 lpw ordering information example lbk 4ft 2 3000lmhe 80cri 40k min10 zt mvolt j12 lbk configurable commercial indoor lithonia way conyers ga 30012 phone 1800705serv 7378 wwwlithoniacom 20202024 acuity brand lighting right reserved rev 041624 lbk led lightbar kit series fixture dimension bar lumen output cri color temperature lbk led lightbar kit 2ft 2 1 1 bar 2 2 bar 3 3 bar 4 4 bar 1600lmhe nominal 1600 lumen high efficiency 12 2000lmhe nominal 2000 lumen high efficiency 123 3000lmhe nominal 3000 lumen high efficiency 23 4000lmhe nominal 4000 lumen high efficiency 23 6000lmhe nominal 6000 lumen high efficiency 34 8000lmhe nominal 8000 lumen high efficiency 4 80cri 80 cri 35k 3500k 40k 4000k 50k 5000k 5 3ft 3 1 1 bar 2 2 bar 1600lmhe nominal 1600 lumen high efficiency 1 2000lmhe nominal 2000 lumen high efficiency 12 3000lmhe nominal 3000 lumen high efficiency 4000lmhe nominal 4000 lumen high efficiency 12 6000lmhe nominal 6000 lumen high efficiency 2 4ft 4 1 1 bar 2 2 bar 3 3 bar 4 4 bar 1600lmhe nominal 1600 lumen high efficiency 1 2000lmhe nominal 2000 lumen high efficiency 12 3000lmhe nominal 3000 lumen high efficiency 123 4000lmhe nominal 4000 lumen high efficiency 1234 6000lmhe nominal 6000 lumen high efficiency 1234 8000lmhe nominal 8000 lumen high efficiency 234 12000lmhe nominal 12000 lumen high efficiency 4 minimum dimming level control input voltage option min10 constant current dimming 10 min1 constant current dimming 1 zt generic 010v dimming 6 ezt eldoled 010v dimming 7 mvolt mvolt 120277v naxx customerspecific option 8 ufc dod unified facility criterion compliant driver 89 fao field adjustable output device j2 job pack 2 kit 1bar 2bar kit 10 j6 job pack 6 kit 4bar kit 10 j12 job pack 12 kit 2bar kit 10 baa buy american act andor build america buy america qualified accessory order separate catalog number ilb cp10 b m20 iota 10 watt constant power high efficiency led emergency driver ca title 2011 lbkxfmr 347v autotransformer10 note 1 available bar qty 1 2 available bar qty 2 3 available bar qty 3 4 available bar qty 4 5 configuration extended leadtimes minimum order quantity apply consult factory 6 available min10 7 available min1 8 consult factory detail availability 9 ordered min10 zt 10 job pack include multiple bar driver hardware single carton 11 fieldinstalled contractor lbk configurable commercial indoor lithonia way conyers ga 30012 phone 1800705serv 7378 wwwlithoniacom 20202024 acuity brand lighting right reserved rev 041624 lbk led lightbar kit emergency battery pack option field installable battery model number wattage runtime minute lumen output 120 lumenswatt ilb cp07 2h 7w 120 840 fema specification ilb cp10 10w 90 1200 ilb cp10 aelr 10w 90 1200 title 20 enabled self testing automated reporting star ilblp cp10 sd 10w 90 1200 title 20 self diagnostic ilblp cp15 sd 15w 90 1800 title 20 self diagnostic ilb cp20 20w 90 2400 title 20 ilb cp20 sd 20w 90 2400 title 20 self diagnostic ul listed product certified field install externalremote fixture minimum delivered lumen output assist product selection increased fixture mounting height cp10 delivered emergency illumination outperforms legacy 1400 lumen fluorescent emergency ballast contact techsupportiotaengineeringcom emergency battery related question enabled star emergency lighting selftesting automated reporting star enables selftesting automated reporting aid life safety code compliance build solution choose preferred deployment mobile star test data logged individual unit broadcast clairity app connected star test data logged star gateway iota emailed directly leave ladder disruption written record emergency lighting solution star life safety code nfpa 101 testing reporting requirement emergency lighting include testing 30 second 30 day testing 90 minute year record keeping report authority having local jurisdiction\n",
      "Similar PDF sentence: feature product sheet ikios t8 tube type c perfect looking retrofit outdated fluorescent ballast enhanced efficiency opting type b light luminaire includes toptier external driver integrated dimming functionality offsetting labor installation expense feature like highefficacy lighting assured compatibility enduring performance tube stand optimal choice swift led upgrade application office school hospital retail store lobby general area residential space note warranty qualification vary item technical data sheet tds specific information product variation listed dlc qualified visit wwwdesignlightsorgsearch confirm qualification published lumen led product approximate vary slightly specification subject change notice photo drawing scale general reference come dimming option 010 v enhanced lighting control suitable use dry damp location low temperature simple uniform design make easier install replace existing fixture reducing cost considerably outfitted highquality external driver delivering soft comfortable lighting infrared uv ray ikio led lighting phone 8445334546 infoikioledlightingcom wwwikioledlightingcom pg 1 t8 tube t y p e c product variation listed page dlc qualified visit httpswwwdesignlightsorgqpl confirm qualification 5 year warranty 5 note warranty qualification vary item technical data sheet tds specific information product variation listed dlc qualified visit wwwdesignlightsorgsearch confirm qualification published lumen led product approximate vary slightly specification subject change notice photo drawing scale general reference ikio led lighting phone 8445334546 infoikioledlightingcom wwwikioledlightingcom pg 2 product ordering detail t8 tube type c t8 tube type c 4ft 15w frosted description power 15 w efficacy 130 lmw dlc t8 tube type c 4ft 15 w 1950 lm 3000 k 100277 v white spec sheet view download 15 w 131 lmw t8 tube type c 4ft 15 w 1965 lm 3500 k 100277 v white view download 15 w 131 lmw t8 tube type c 4ft 15 w 1965 lm 4000 k 100277 v white view download 15 w 132 lmw t8 tube type c 4ft 15 w 1980 lm 4500 k 100277 v white view download 15 w 132 lmw t8 tube type c 4ft 15 w 1980 lm 5000 k 100277 v white view download sku number 662187533865 662187533889 662187533872 662187533896 662187533902 t8 tube type c 4ft 15w clear description power 15 w efficacy 140 lmw dlc t8 tube type c 4ft 15 w 2100 lm 3000 k 100277 v white spec sheet view download 15 w 141 lmw t8 tube type c 4ft 15 w 2115 lm 3500 k 100277 v white view download 15 w 141 lmw t8 tube type c 4ft 15 w 2115 lm 4000 k 100277 v white view download 15 w 141 lmw t8 tube type c 4ft 15 w 2115 lm 4500 k 100277 v white view download 15 w 141 lmw t8 tube type c 4ft 15 w 2115 lm 5000 k 100277 v white view download sku number 662187533858 662187540641 662187540627 662187540634 662187540610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the Sentence-BERT model once at the start\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation, convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    \n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "# Function to generate n-grams from text\n",
    "def generate_ngrams(text, n=2):\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "# Function to compute embeddings for a list of sentences\n",
    "def compute_embeddings(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "# Function to compute similarity score between all sentences in two documents\n",
    "def find_similar_sentences(embedding1, sentences1, embedding2, sentences2):\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = util.cos_sim(embedding1, embedding2)\n",
    "\n",
    "    # Find the highest similarity score pairs\n",
    "    most_similar_pairs = []\n",
    "    for i in range(len(sentences1)):\n",
    "        for j in range(len(sentences2)):\n",
    "            similarity_score = cosine_sim_matrix[i][j].item()\n",
    "            most_similar_pairs.append((similarity_score, sentences1[i], sentences2[j]))\n",
    "\n",
    "    # Sort the pairs by similarity score in descending order\n",
    "    most_similar_pairs = sorted(most_similar_pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    return most_similar_pairs\n",
    "\n",
    "# Function to process a single PDF file and calculate its similarity details\n",
    "def process_pdf(file_info):\n",
    "    input_sentences, input_embedding, input_pdf_path, pdf_path = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    \n",
    "    # Split text into sentences\n",
    "    folder_sentences = sent_tokenize(folder_pdf_text)\n",
    "\n",
    "    # Compute embeddings for the folder PDF sentences\n",
    "    folder_pdf_embedding = compute_embeddings(folder_sentences)\n",
    "    \n",
    "    # Find similar sentences between the input PDF and the current folder PDF\n",
    "    similar_sentences = find_similar_sentences(input_embedding, input_sentences, folder_pdf_embedding, folder_sentences)\n",
    "    \n",
    "    # Return the most similar sentences and their similarity scores\n",
    "    return (pdf_path, similar_sentences[:5])  # Return top 5 most similar sentences for brevity\n",
    "\n",
    "# Function to find the most similar PDF in a folder using Sentence-BERT embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Split input text into sentences\n",
    "    input_sentences = sent_tokenize(input_text)\n",
    "    \n",
    "    # Compute embeddings for input PDF sentences\n",
    "    input_embedding = compute_embeddings(input_sentences)\n",
    "\n",
    "    # List all PDF files in the folder\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    most_similar_details = None\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_pdf, [(input_sentences, input_embedding, input_pdf_path, pdf_path) for pdf_path in pdf_files])\n",
    "\n",
    "    # Process results to find the most similar PDF\n",
    "    for pdf_path, similar_sentences in results:\n",
    "        avg_similarity = sum([score for score, _, _ in similar_sentences]) / len(similar_sentences)\n",
    "        if avg_similarity > max_similarity:\n",
    "            max_similarity = avg_similarity\n",
    "            most_similar_pdf = os.path.basename(pdf_path)\n",
    "            most_similar_details = similar_sentences\n",
    "\n",
    "    return most_similar_pdf, max_similarity, most_similar_details\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity, similar_details = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "\n",
    "    if most_similar_pdf:\n",
    "        print(f\"The most similar PDF is: {most_similar_pdf} with an average similarity score of {similarity:.2f}\")\n",
    "        print(\"\\nTop 5 most similar sentences or details:\")\n",
    "        for score, sent1, sent2 in similar_details:\n",
    "            print(f\"Score: {score:.2f}\")\n",
    "            print(f\"Input PDF sentence: {sent1}\")\n",
    "            print(f\"Similar PDF sentence: {sent2}\\n\")\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144aff9a-1d56-4d84-91ae-6e0819a45144",
   "metadata": {},
   "source": [
    "The output is not really understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0dc6fe43-059f-4089-8e61-60fc2d106f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: T8_Tube_Type_C_PS.pdf with an average similarity score of 0.82\n",
      "\n",
      "Top 5 most similar sentences or details:\n",
      "\n",
      "Match 1:\n",
      "Similarity Score: 0.82\n",
      "Input PDF Sentence: lbk lightbar kit led retrofit lbk commercial indoor lbk configurable catalog number note type feature specification intended use lbk kit provides simple costeffective integrated led solution retrofit nearly fluorescent fixture t8 t12 t5 lamp lightbar kit provide reliability thermal performance longe...\n",
      "Similar PDF Sentence: feature product sheet ikios t8 tube type c perfect looking retrofit outdated fluorescent ballast enhanced efficiency opting type b light luminaire includes toptier external driver integrated dimming functionality offsetting labor installation expense feature like highefficacy lighting assured compat...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the Sentence-BERT model once at the start\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation, convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    \n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "# Function to generate n-grams from text\n",
    "def generate_ngrams(text, n=2):\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "# Function to compute embeddings for a list of sentences\n",
    "def compute_embeddings(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "# Function to compute similarity score between all sentences in two documents\n",
    "def find_similar_sentences(embedding1, sentences1, embedding2, sentences2):\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = util.cos_sim(embedding1, embedding2)\n",
    "\n",
    "    # Find the highest similarity score pairs\n",
    "    most_similar_pairs = []\n",
    "    for i in range(len(sentences1)):\n",
    "        for j in range(len(sentences2)):\n",
    "            similarity_score = cosine_sim_matrix[i][j].item()\n",
    "            most_similar_pairs.append((similarity_score, sentences1[i], sentences2[j]))\n",
    "\n",
    "    # Sort the pairs by similarity score in descending order\n",
    "    most_similar_pairs = sorted(most_similar_pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    return most_similar_pairs\n",
    "\n",
    "# Function to process a single PDF file and calculate its similarity details\n",
    "def process_pdf(file_info):\n",
    "    input_sentences, input_embedding, input_pdf_path, pdf_path = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    \n",
    "    # Split text into sentences\n",
    "    folder_sentences = sent_tokenize(folder_pdf_text)\n",
    "\n",
    "    # Compute embeddings for the folder PDF sentences\n",
    "    folder_pdf_embedding = compute_embeddings(folder_sentences)\n",
    "    \n",
    "    # Find similar sentences between the input PDF and the current folder PDF\n",
    "    similar_sentences = find_similar_sentences(input_embedding, input_sentences, folder_pdf_embedding, folder_sentences)\n",
    "    \n",
    "    # Return the most similar sentences and their similarity scores\n",
    "    return (pdf_path, similar_sentences[:5])  # Return top 5 most similar sentences for brevity\n",
    "\n",
    "# Function to find the most similar PDF in a folder using Sentence-BERT embeddings\n",
    "def find_most_similar_pdf(input_pdf_path, folder_path):\n",
    "    # Extract and preprocess text from the input PDF\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    \n",
    "    # Split input text into sentences\n",
    "    input_sentences = sent_tokenize(input_text)\n",
    "    \n",
    "    # Compute embeddings for input PDF sentences\n",
    "    input_embedding = compute_embeddings(input_sentences)\n",
    "\n",
    "    # List all PDF files in the folder\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    most_similar_details = None\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Map the process_pdf function to each PDF file\n",
    "        results = executor.map(process_pdf, [(input_sentences, input_embedding, input_pdf_path, pdf_path) for pdf_path in pdf_files])\n",
    "\n",
    "        # Process results to find the most similar PDF\n",
    "        for result in results:\n",
    "            pdf_path, similar_sentences = result\n",
    "            avg_similarity = sum([score for score, _, _ in similar_sentences]) / len(similar_sentences) if similar_sentences else 0\n",
    "            if avg_similarity > max_similarity:\n",
    "                max_similarity = avg_similarity\n",
    "                most_similar_pdf = os.path.basename(pdf_path)\n",
    "                most_similar_details = similar_sentences\n",
    "\n",
    "    return most_similar_pdf, max_similarity, most_similar_details\n",
    "\n",
    "# Function to format and display the similarity results\n",
    "def format_similarity_results(input_pdf_path, most_similar_pdf, similarity, similar_details):\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with an average similarity score of {similarity:.2f}\\n\")\n",
    "    \n",
    "    print(\"Top 5 most similar sentences or details:\\n\")\n",
    "    \n",
    "    for idx, (score, sent1, sent2) in enumerate(similar_details[:5], start=1):  # Limit to top 5\n",
    "        print(f\"Match {idx}:\")\n",
    "        print(f\"Similarity Score: {score:.2f}\")\n",
    "        print(f\"Input PDF Sentence: {sent1[:300]}...\")  # Print the first 300 characters for brevity\n",
    "        print(f\"Similar PDF Sentence: {sent2[:300]}...\")  # Print the first 300 characters for brevity\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Main function to handle the PDF similarity search\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the input PDF and folder containing other PDFs\n",
    "    input_pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//lbk-configurable.pdf\"  # Replace with the path to the input PDF\n",
    "    folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Replace with the path to the folder containing PDFs\n",
    "\n",
    "    # Find the most similar PDF\n",
    "    most_similar_pdf, similarity, similar_details = find_most_similar_pdf(input_pdf_path, folder_path)\n",
    "\n",
    "    if most_similar_pdf:\n",
    "        format_similarity_results(input_pdf_path, most_similar_pdf, similarity, similar_details)\n",
    "    else:\n",
    "        print(\"No similar PDF found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950afe78-7a28-4cbf-9a25-448c9c320c71",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552e91d-870c-40c8-a3eb-8d4e843f1e87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59abf7-7cbf-4752-ac97-0639bd0d28aa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5f9ebb-d5cf-424e-bfa8-1a8b64acd101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from threading import Thread\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize Sentence-BERT model and other required objects\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for SIFT.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using SIFT.\"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    return len(matches)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            text += doc[page_num].get_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text by removing punctuation, lowercasing, and lemmatizing.\"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    tokens = [word for word in word_tokenize(text) if word not in ENGLISH_STOP_WORDS]\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text.strip()\n",
    "\n",
    "def generate_ngrams(text, n=2):\n",
    "    \"\"\"Generates n-grams from text.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(ngram) for ngram in ngrams_list]\n",
    "\n",
    "def compute_embedding(text):\n",
    "    \"\"\"Computes the embeddings of text using Sentence-BERT.\"\"\"\n",
    "    sentences = text.split('. ')\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    \"\"\"Computes the similarity score between two sets of embeddings.\"\"\"\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.max().item()\n",
    "\n",
    "def process_pdf(file_info, input_embedding, update_progress, total_pdfs):\n",
    "    \"\"\"Processes a single PDF file and calculates its similarity score.\"\"\"\n",
    "    input_pdf_path, pdf_path, idx = file_info\n",
    "    folder_pdf_text = preprocess_text(extract_text_from_pdf(pdf_path))\n",
    "    bigrams = generate_ngrams(folder_pdf_text, 2)\n",
    "    enriched_text = ' '.join([folder_pdf_text] + bigrams)\n",
    "    folder_pdf_embedding = compute_embedding(enriched_text)\n",
    "    similarity = compute_similarity(input_embedding, folder_pdf_embedding)\n",
    "    \n",
    "    # Update progress\n",
    "    progress = (idx + 1) / total_pdfs * 100\n",
    "    update_progress(progress)\n",
    "    \n",
    "    return (pdf_path, similarity)\n",
    "\n",
    "def find_most_similar_pdf_by_text(input_pdf_path, folder_path, update_progress):\n",
    "    \"\"\"Finds the PDF with the most similar text content to the input PDF using Sentence-BERT embeddings.\"\"\"\n",
    "    input_text = preprocess_text(extract_text_from_pdf(input_pdf_path))\n",
    "    bigrams = generate_ngrams(input_text, 2)\n",
    "    enriched_text = ' '.join([input_text] + bigrams)\n",
    "    input_embedding = compute_embedding(enriched_text)\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    max_similarity = -1\n",
    "    most_similar_pdf = None\n",
    "    total_pdfs = len(pdf_files)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(lambda file_info: process_pdf(file_info, input_embedding, update_progress, total_pdfs),\n",
    "                               [(input_pdf_path, pdf_path, idx) for idx, pdf_path in enumerate(pdf_files)])\n",
    "    \n",
    "    for pdf_path, similarity in results:\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pdf = os.path.basename(pdf_path)\n",
    "    \n",
    "    return most_similar_pdf, max_similarity\n",
    "\n",
    "def find_most_similar_pdf_by_image(input_image_path, folder_path, update_progress):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    \n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    # Use os.walk to find all PDFs in the folder and its subfolders\n",
    "    pdf_files = []\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "    total_pdfs = len(pdf_files)\n",
    "\n",
    "    for idx, pdf_file in enumerate(pdf_files):\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        extracted_images = extract_images_from_pdf(pdf_path)\n",
    "        for img in extracted_images:\n",
    "            img_features = extract_image_features(img)\n",
    "            similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "            keypoint_match_count = match_keypoints(input_image, img)\n",
    "            combined_score = similarity + (keypoint_match_count / 1000)\n",
    "            if combined_score > highest_similarity:\n",
    "                highest_similarity = combined_score\n",
    "                most_similar_pdf = pdf_file\n",
    "        \n",
    "        # Update progress\n",
    "        progress = (idx + 1) / total_pdfs * 100\n",
    "        update_progress(progress)\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "def select_image_file():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select Image File\",\n",
    "        filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.tiff\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        image_file_entry.delete(0, tk.END)\n",
    "        image_file_entry.insert(0, file_path)\n",
    "        display_image(file_path)\n",
    "\n",
    "def select_pdf_file():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select PDF File\",\n",
    "        filetypes=[(\"PDF Files\", \"*.pdf\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        pdf_file_entry.delete(0, tk.END)\n",
    "        pdf_file_entry.insert(0, file_path)\n",
    "\n",
    "def select_folder():\n",
    "    folder_path = filedialog.askdirectory(title=\"Select Folder Containing PDFs\")\n",
    "    if folder_path:\n",
    "        folder_entry.delete(0, tk.END)\n",
    "        folder_entry.insert(0, folder_path)\n",
    "\n",
    "def display_image(image_path):\n",
    "    \"\"\"Display the selected image on the UI.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image.thumbnail((200, 200))  # Resize image to fit within 200x200 pixels\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    image_label.config(image=photo)\n",
    "    image_label.image = photo  # Keep a reference to avoid garbage collection\n",
    "\n",
    "def update_progress_bar(progress):\n",
    "    \"\"\"Update the progress bar and status label.\"\"\"\n",
    "    progress_bar['value'] = progress\n",
    "    status_label.config(text=f\"Processing: {progress:.2f}%\")\n",
    "\n",
    "def start_image_similarity_search():\n",
    "    input_image_path = image_file_entry.get()\n",
    "    folder_path = folder_entry.get()\n",
    "    if not input_image_path or not folder_path:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please provide both the image file and folder paths.\")\n",
    "        return\n",
    "    \n",
    "    def run_search():\n",
    "        status_label.config(text=\"Processing image similarity...\")\n",
    "        progress_bar.config(mode=\"determinate\")\n",
    "        progress_bar['value'] = 0\n",
    "        result, similarity = find_most_similar_pdf_by_image(input_image_path, folder_path, update_progress_bar)\n",
    "        result_label.config(text=f\"Most similar PDF on the basis of input image: {result} (Similarity: {similarity:.2f})\")\n",
    "        status_label.config(text=\"Search Complete!\")\n",
    "    \n",
    "    Thread(target=run_search).start()\n",
    "\n",
    "def start_text_similarity_search():\n",
    "    input_pdf_path = pdf_file_entry.get()\n",
    "    folder_path = folder_entry.get()\n",
    "    if not input_pdf_path or not folder_path:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please provide both the PDF file and folder paths.\")\n",
    "        return\n",
    "    \n",
    "    def run_search():\n",
    "        status_label.config(text=\"Processing text similarity...\")\n",
    "        progress_bar.config(mode=\"determinate\")\n",
    "        progress_bar['value'] = 0\n",
    "        result, similarity = find_most_similar_pdf_by_text(input_pdf_path, folder_path, update_progress_bar)\n",
    "        result_label.config(text=f\"Most similar PDF on the basis of input text: {result} (Similarity: {similarity:.2f})\")\n",
    "        status_label.config(text=\"Search Complete!\")\n",
    "    \n",
    "    Thread(target=run_search).start()\n",
    "\n",
    "# Create the main Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"PDF Similarity Search\")\n",
    "root.geometry(\"600x500\")\n",
    "root.resizable(True, True)\n",
    "\n",
    "# Image similarity section\n",
    "image_file_label = ttk.Label(root, text=\"Select Image File:\")\n",
    "image_file_label.grid(row=0, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "image_file_entry = ttk.Entry(root, width=40)\n",
    "image_file_entry.grid(row=0, column=1, padx=10, pady=10)\n",
    "image_file_button = ttk.Button(root, text=\"Browse\", command=select_image_file)\n",
    "image_file_button.grid(row=0, column=2, padx=10, pady=10)\n",
    "\n",
    "# Display image\n",
    "image_label = ttk.Label(root)\n",
    "image_label.grid(row=1, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "# Text similarity section\n",
    "pdf_file_label = ttk.Label(root, text=\"Select PDF File:\")\n",
    "pdf_file_label.grid(row=2, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "pdf_file_entry = ttk.Entry(root, width=40)\n",
    "pdf_file_entry.grid(row=2, column=1, padx=10, pady=10)\n",
    "pdf_file_button = ttk.Button(root, text=\"Browse\", command=select_pdf_file)\n",
    "pdf_file_button.grid(row=2, column=2, padx=10, pady=10)\n",
    "\n",
    "# Folder selection section\n",
    "folder_label = ttk.Label(root, text=\"Select Folder Containing PDFs:\")\n",
    "folder_label.grid(row=3, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "folder_entry = ttk.Entry(root, width=40)\n",
    "folder_entry.grid(row=3, column=1, padx=10, pady=10)\n",
    "folder_button = ttk.Button(root, text=\"Browse\", command=select_folder)\n",
    "folder_button.grid(row=3, column=2, padx=10, pady=10)\n",
    "\n",
    "# Buttons to start similarity searches\n",
    "image_similarity_button = ttk.Button(root, text=\"Find Most Similar PDF by Image\", command=start_image_similarity_search)\n",
    "image_similarity_button.grid(row=4, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "text_similarity_button = ttk.Button(root, text=\"Find Most Similar PDF by Text\", command=start_text_similarity_search)\n",
    "text_similarity_button.grid(row=5, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "# Result label\n",
    "result_label = ttk.Label(root, text=\"\")\n",
    "result_label.grid(row=6, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = ttk.Progressbar(root, orient=\"horizontal\", mode=\"determinate\", length=280)\n",
    "progress_bar.grid(row=7, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "# Status label\n",
    "status_label = ttk.Label(root, text=\"\", wraplength=400)\n",
    "status_label.grid(row=8, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "# Run the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79ff45-0ef6-48ca-9aaf-b40ce7bc897a",
   "metadata": {},
   "source": [
    "# THE PROJECT IS COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a18a22-7561-4caf-92c5-40b70edeb568",
   "metadata": {},
   "source": [
    "###### TnC: Consistent improvements are being made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
