{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52640a6e-c403-4166-9456-71def4853de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Finetuning the Image Similarity Part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc83741-23a3-4c24-adde-6a544d4d9f8a",
   "metadata": {},
   "source": [
    "This is the initial Image Similarity finder code. It is apparently not in its optimum condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84b3061-7ebd-4dad-9d95-40683d7b1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Rodella_UFO_Black_150W_3500K_100-277 V_TDS.pdf with a similarity score of: 1.29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for SIFT.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using SIFT.\"\"\"\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                \n",
    "                # Use keypoint matching with SIFT\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches\n",
    "                combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//Wall_Pack_Two.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71747d6-4e94-4a0d-a16d-0a2e9a490217",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acbb2f-d4b8-4fb1-9c79-cb67ea0819a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ORB instead of SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd36ec-f280-4f2e-be2b-3c8cd75439c4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f868a6-edd8-4e21-bd8d-eba14c497f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Delphi_WP_SC_21W28W34.98W_DLC_TDS.pdf with a similarity score of: 0.91\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def extract_image_features_batch(images):\n",
    "    \"\"\"Extracts deep learning features from a batch of images using ResNet.\"\"\"\n",
    "    input_tensors = torch.stack([preprocess(image) for image in images])  # Create a batch of images\n",
    "    with torch.no_grad():\n",
    "        features_batch = resnet_model(input_tensors)\n",
    "    return features_batch.numpy()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for ORB.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using ORB.\"\"\"\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher with Hamming distance (since ORB uses binary descriptors)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def process_pdf_in_parallel(pdf_file, input_image_features, input_image, folder_path):\n",
    "    \"\"\"Processes a single PDF file to find the most similar image.\"\"\"\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "        # Use keypoint matching with ORB\n",
    "        keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "        # Combine similarity and keypoint matches\n",
    "        combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "        return pdf_file, combined_score\n",
    "    \n",
    "    return pdf_file, -1  # Default score if no image found\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pdf_in_parallel, pdf_file, input_image_features, input_image, folder_path)\n",
    "                   for pdf_file in os.listdir(folder_path) if pdf_file.endswith(\".pdf\")]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    # Get the PDF with the highest combined score\n",
    "    most_similar_pdf, highest_similarity = max(results, key=lambda x: x[1])\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//81YkGfZe7PL._AC_UF1000,1000_QL80_.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a058711-e75e-43dc-8cb2-7c8c15f50ed1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d479b6-56e2-462f-b526-1b5ccccd8d2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## AKAZE instead of SIFT or ORB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4838d1-d757-47da-961c-eac6108319a7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d9af55-b7aa-40cf-84ae-0ba1bf3201e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Rodella_UFO_Black_150W_3500K_100-277 V_TDS.pdf with a similarity score of: 1.07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def extract_image_features_batch(images):\n",
    "    \"\"\"Extracts deep learning features from a batch of images using ResNet.\"\"\"\n",
    "    input_tensors = torch.stack([preprocess(image) for image in images])  # Create a batch of images\n",
    "    with torch.no_grad():\n",
    "        features_batch = resnet_model(input_tensors)\n",
    "    return features_batch.numpy()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for AKAZE.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using AKAZE.\"\"\"\n",
    "    # Initialize AKAZE detector\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = akaze.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = akaze.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors (Hamming norm is used for binary descriptors)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def process_pdf_in_parallel(pdf_file, input_image_features, input_image, folder_path):\n",
    "    \"\"\"Processes a single PDF file to find the most similar image.\"\"\"\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "        # Use keypoint matching with AKAZE\n",
    "        keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "        # Combine similarity and keypoint matches\n",
    "        combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "        return pdf_file, combined_score\n",
    "    \n",
    "    return pdf_file, -1  # Default score if no image found\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pdf_in_parallel, pdf_file, input_image_features, input_image, folder_path)\n",
    "                   for pdf_file in os.listdir(folder_path) if pdf_file.endswith(\".pdf\")]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    # Get the PDF with the highest combined score\n",
    "    most_similar_pdf, highest_similarity = max(results, key=lambda x: x[1])\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//81YkGfZe7PL._AC_UF1000,1000_QL80_.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f49c7-3e77-46af-80c8-21d2db35ada6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079646ad-3834-4d91-b0a8-4f5aa6ee0bd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a6b5d1-a355-433a-8cfe-78e4d8145e67",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93191aa1-5d38-42db-8bc6-d1076fad960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Forza Explosion Proof Square High Bay.pdf with a similarity score of: 1.80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def extract_image_features_batch(images):\n",
    "    \"\"\"Extracts deep learning features from a batch of images using ResNet.\"\"\"\n",
    "    input_tensors = torch.stack([preprocess(image) for image in images])  # Create a batch of images\n",
    "    with torch.no_grad():\n",
    "        features_batch = resnet_model(input_tensors)\n",
    "    return features_batch.numpy()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for BRISK.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using BRISK.\"\"\"\n",
    "    # Initialize BRISK detector\n",
    "    brisk = cv2.BRISK_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = brisk.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = brisk.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors (Hamming norm is used for binary descriptors)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def process_pdf_in_parallel(pdf_file, input_image_features, input_image, folder_path):\n",
    "    \"\"\"Processes a single PDF file to find the most similar image.\"\"\"\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "        # Use keypoint matching with BRISK\n",
    "        keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "        # Combine similarity and keypoint matches\n",
    "        combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "        return pdf_file, combined_score\n",
    "    \n",
    "    return pdf_file, -1  # Default score if no image found\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pdf_in_parallel, pdf_file, input_image_features, input_image, folder_path)\n",
    "                   for pdf_file in os.listdir(folder_path) if pdf_file.endswith(\".pdf\")]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    # Get the PDF with the highest combined score\n",
    "    most_similar_pdf, highest_similarity = max(results, key=lambda x: x[1])\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//81YkGfZe7PL._AC_UF1000,1000_QL80_.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6782be2-ebdc-4fa3-85e2-6cb9903c04ea",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dde19-7956-40d8-915a-a85be82f1334",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FAST and FREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7b536-d721-47ae-b15e-b3a0ab4b6836",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bee6766-ffab-41d4-898d-b2a19a517610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Rodella_UFO_Black_150W_3500K_100-277 V_TDS.pdf with a similarity score of: 2.53\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def extract_image_features_batch(images):\n",
    "    \"\"\"Extracts deep learning features from a batch of images using ResNet.\"\"\"\n",
    "    input_tensors = torch.stack([preprocess(image) for image in images])  # Create a batch of images\n",
    "    with torch.no_grad():\n",
    "        features_batch = resnet_model(input_tensors)\n",
    "    return features_batch.numpy()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for FAST and FREAK.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using FAST and FREAK.\"\"\"\n",
    "    # Initialize FAST detector\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "    # Initialize FREAK descriptor\n",
    "    freak = cv2.xfeatures2d.FREAK_create()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "    \n",
    "    # Detect keypoints using FAST\n",
    "    keypoints1 = fast.detect(image1_gray, None)\n",
    "    keypoints2 = fast.detect(image2_gray, None)\n",
    "\n",
    "    # Compute FREAK descriptors\n",
    "    keypoints1, descriptors1 = freak.compute(image1_gray, keypoints1)\n",
    "    keypoints2, descriptors2 = freak.compute(image2_gray, keypoints2)\n",
    "    \n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors (Hamming norm is used for binary descriptors)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "def process_pdf_in_parallel(pdf_file, input_image_features, input_image, folder_path):\n",
    "    \"\"\"Processes a single PDF file to find the most similar image.\"\"\"\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "        # Use keypoint matching with FAST and FREAK\n",
    "        keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "        # Combine similarity and keypoint matches\n",
    "        combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "        return pdf_file, combined_score\n",
    "    \n",
    "    return pdf_file, -1  # Default score if no image found\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pdf_in_parallel, pdf_file, input_image_features, input_image, folder_path)\n",
    "                   for pdf_file in os.listdir(folder_path) if pdf_file.endswith(\".pdf\")]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    # Get the PDF with the highest combined score\n",
    "    most_similar_pdf, highest_similarity = max(results, key=lambda x: x[1])\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//Wall_Pack_Two.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069ee0f-2283-4bcd-8170-f12be3a96733",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17945d-bcf3-49d4-a2cc-aaff3a34b9d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## KAZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6008b6a-50f0-4b01-8535-b930073d8804",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe3557b-dae8-42f7-b42a-7a721f23c3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Magnus_AFL_100W150W205W_TDS.pdf with a similarity score of: 0.77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load pre-trained deep learning model (ResNet-50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for ResNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by ResNet\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet standards\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep learning features from an image using ResNet.\"\"\"\n",
    "    # Convert PIL Image to PyTorch Tensor\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features using ResNet\n",
    "        features = resnet_model(input_batch)\n",
    "    \n",
    "    return features.numpy().flatten()\n",
    "\n",
    "def extract_image_features_batch(images):\n",
    "    \"\"\"Extracts deep learning features from a batch of images using ResNet.\"\"\"\n",
    "    input_tensors = torch.stack([preprocess(image) for image in images])  # Create a batch of images\n",
    "    with torch.no_grad():\n",
    "        features_batch = resnet_model(input_tensors)\n",
    "    return features_batch.numpy()\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for KAZE.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using KAZE.\"\"\"\n",
    "    # Initialize KAZE detector\n",
    "    kaze = cv2.KAZE_create()\n",
    "\n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = kaze.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = kaze.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    # If no descriptors are found, return 0 matches\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "    \n",
    "    # Use BFMatcher to match descriptors (L2 norm is typically used for KAZE)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    return len(matches)\n",
    "\n",
    "def process_pdf_in_parallel(pdf_file, input_image_features, input_image, folder_path):\n",
    "    \"\"\"Processes a single PDF file to find the most similar image.\"\"\"\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    for img in extracted_images:\n",
    "        img_features = extract_image_features(img)\n",
    "        similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "\n",
    "        # Use keypoint matching with KAZE\n",
    "        keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "        # Combine similarity and keypoint matches\n",
    "        combined_score = similarity + (keypoint_match_count / 1000)  # Normalize keypoint matches\n",
    "        return pdf_file, combined_score\n",
    "    \n",
    "    return pdf_file, -1  # Default score if no image found\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "    \n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pdf_in_parallel, pdf_file, input_image_features, input_image, folder_path)\n",
    "                   for pdf_file in os.listdir(folder_path) if pdf_file.endswith(\".pdf\")]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    # Get the PDF with the highest combined score\n",
    "    most_similar_pdf, highest_similarity = max(results, key=lambda x: x[1])\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//Wall_Pack_Two.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.2f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a6d84-4936-4600-87da-26d4a93a2b0e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779d5e9-df7d-4fc0-b6a9-6d216a507088",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BACKBONE 1: Image Similarity\n",
    "#### The other models are not getting the right results, therefore we start working on the existing model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9722120-9196-4f6f-9042-3cdcce5a4431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Orwin_DL_10inch_TDS.pdf with a similarity score of: 0.5072\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained VGG-19 model\n",
    "vgg_model = models.vgg19(pretrained=True)\n",
    "vgg_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Image preprocessing transformations for VGG\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by the model\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize using ImageNet standards\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts images from a PDF file.\"\"\"\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_intermediate_features(image, model, layer):\n",
    "    \"\"\"Extract intermediate deep learning features from an image.\"\"\"\n",
    "    # Dictionary to store the output\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['output'] = output\n",
    "\n",
    "    # Register hook for intermediate layer\n",
    "    handle = model._modules.get(layer).register_forward_hook(hook_fn)\n",
    "\n",
    "    # Preprocess image\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    # Get the features from the hook\n",
    "    intermediate_features = activation['output']\n",
    "\n",
    "    # Remove the hook\n",
    "    handle.remove()\n",
    "\n",
    "    return intermediate_features.flatten().numpy()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extracts deep and hand-crafted features.\"\"\"\n",
    "    vgg_features = extract_intermediate_features(image, vgg_model, 'features')  # Early VGG features\n",
    "    hog_features = extract_hog_features(image)                                  # HOG features\n",
    "    return np.concatenate([vgg_features, hog_features])\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    \"\"\"Calculates the similarity between two image feature vectors using cosine similarity.\"\"\"\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the image for keypoint detectors.\"\"\"\n",
    "    # Resize image to a fixed size\n",
    "    image = image.resize((300, 300))  # You can adjust the size as needed\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Convert to uint8 format\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    \"\"\"Match keypoints between two images using KAZE and ORB detectors.\"\"\"\n",
    "    # Initialize KAZE and ORB detectors\n",
    "    kaze = cv2.KAZE_create()\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Preprocess images\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    # Detect keypoints and compute descriptors with both KAZE and ORB\n",
    "    keypoints1_kaze, descriptors1_kaze = kaze.detectAndCompute(image1_gray, None)\n",
    "    keypoints2_kaze, descriptors2_kaze = kaze.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    keypoints1_orb, descriptors1_orb = orb.detectAndCompute(image1_gray, None)\n",
    "    keypoints2_orb, descriptors2_orb = orb.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    # Initialize match counts\n",
    "    matches_kaze_count = 0\n",
    "    matches_orb_count = 0\n",
    "\n",
    "    # Match KAZE descriptors\n",
    "    if descriptors1_kaze is not None and descriptors2_kaze is not None:\n",
    "        bf_kaze = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        matches_kaze = bf_kaze.match(descriptors1_kaze, descriptors2_kaze)\n",
    "        matches_kaze_count = len(matches_kaze)\n",
    "\n",
    "    # Match ORB descriptors\n",
    "    if descriptors1_orb is not None and descriptors2_orb is not None:\n",
    "        bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches_orb = bf_orb.match(descriptors1_orb, descriptors2_orb)\n",
    "        matches_orb_count = len(matches_orb)\n",
    "\n",
    "    # Return the combined number of matches\n",
    "    return matches_kaze_count + matches_orb_count\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    \"\"\"Extracts Histogram of Oriented Gradients (HOG) features from an image.\"\"\"\n",
    "    # Resize image to a fixed size\n",
    "    image = image.resize((128, 128))  # Ensure all images are the same size\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "\n",
    "    # Compute HOG descriptors\n",
    "    hog_features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(1, 1), visualize=False, feature_vector=True)\n",
    "    \n",
    "    return hog_features\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    \"\"\"Finds the PDF with the most similar image to the input image.\"\"\"\n",
    "    input_image = Image.open(input_image_path)\n",
    "\n",
    "    # Convert input image to RGB if necessary\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    # Extract features from the input image using VGG and HOG\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                # Convert image to RGB if necessary\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "\n",
    "                # Extract features using VGG and HOG\n",
    "                img_features = extract_image_features(img)\n",
    "\n",
    "                # Calculate cosine similarity\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                \n",
    "                # Use keypoint matching with KAZE and ORB\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Combine similarity and keypoint matches (with appropriate weights)\n",
    "                combined_score = (0.7 * similarity +\n",
    "                                  0.3 * (keypoint_match_count / 1000))  # Normalized keypoint matches\n",
    "\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test3.jpg\"  # Provide the path to the input image\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Provide the path to the folder with PDFs\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8010b2-fd3c-42d6-8939-063f1e2cd077",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51156093-f8d1-4ea6-89b6-f841631a5b49",
   "metadata": {},
   "source": [
    "The results have less accuracy but now they are much better performing in terms of light category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c288a-1a7d-4a79-acde-107c27bf7f4a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63672b8-0426-41a9-8588-8064ca3b4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar PDF is: Edin_WP_SC_30W40W50W60W_30K40K50K_TDS.pdf with a similarity score of: 0.2744\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained VGG-19 and ResNet models\n",
    "vgg_model = models.vgg19(pretrained=True)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "vgg_model.eval()\n",
    "resnet_model.eval()\n",
    "\n",
    "# Image preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_intermediate_features(image, model, layer):\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['output'] = output\n",
    "\n",
    "    handle = model._modules.get(layer).register_forward_hook(hook_fn)\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    intermediate_features = activation['output']\n",
    "    handle.remove()\n",
    "\n",
    "    return intermediate_features.flatten().numpy()\n",
    "\n",
    "def extract_resnet_features(image):\n",
    "    \"\"\"Extract features using ResNet.\"\"\"\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        resnet_features = resnet_model(input_tensor)\n",
    "    return resnet_features.flatten().numpy()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extract combined VGG, ResNet, and HOG features.\"\"\"\n",
    "    vgg_features = extract_intermediate_features(image, vgg_model, 'features')\n",
    "    resnet_features = extract_resnet_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "\n",
    "    # Assign different weights to each feature set\n",
    "    vgg_weight = 0.5\n",
    "    resnet_weight = 0.3\n",
    "    hog_weight = 0.2\n",
    "\n",
    "    # Combine all features with weights\n",
    "    combined_features = np.concatenate([\n",
    "        vgg_features * vgg_weight, \n",
    "        resnet_features * resnet_weight, \n",
    "        hog_features * hog_weight\n",
    "    ])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = image.resize((128, 128))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "\n",
    "    hog_features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(1, 1), visualize=False, feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    if features1.size == 0 or features2.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    features1 = features1.reshape(1, -1)\n",
    "    features2 = features2.reshape(1, -1)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((300, 300))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "def find_most_similar_pdf(input_image_path, folder_path):\n",
    "    input_image = Image.open(input_image_path)\n",
    "\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "\n",
    "    most_similar_pdf = None\n",
    "    highest_similarity = -1\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Adjust the weighting of similarity and keypoints for better matching\n",
    "                combined_score = (0.7 * similarity + 0.3 * (keypoint_match_count / 1000))\n",
    "\n",
    "                if combined_score > highest_similarity:\n",
    "                    highest_similarity = combined_score\n",
    "                    most_similar_pdf = pdf_file\n",
    "\n",
    "    return most_similar_pdf, highest_similarity\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//Wall_Pack_Two.jpg\"\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "\n",
    "most_similar_pdf, similarity_score = find_most_similar_pdf(input_image_path, folder_path)\n",
    "\n",
    "if most_similar_pdf:\n",
    "    print(f\"The most similar PDF is: {most_similar_pdf} with a similarity score of: {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce326ccb-21af-419a-82b0-389f7019ec7f",
   "metadata": {},
   "source": [
    "The image similarity finder is way better than what was used in V1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dff7dc-12bf-4c55-9820-ce335c38fe3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Adding feature of finding more than 1 similar pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffd665d-c9c0-4971-a8ec-a495c6a65883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: Coloris_RGBW_ELPL_PS.pdf with similarity score: 0.5315\n",
      "PDF: Delphi_PL_2x4FT_504030W_504035K_DLC_TDS.pdf with similarity score: 0.4395\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained VGG-19 and ResNet models\n",
    "vgg_model = models.vgg19(pretrained=True)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "vgg_model.eval()\n",
    "resnet_model.eval()\n",
    "\n",
    "# Image preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_intermediate_features(image, model, layer):\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['output'] = output\n",
    "\n",
    "    handle = model._modules.get(layer).register_forward_hook(hook_fn)\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    intermediate_features = activation['output']\n",
    "    handle.remove()\n",
    "\n",
    "    return intermediate_features.flatten().numpy()\n",
    "\n",
    "def extract_resnet_features(image):\n",
    "    \"\"\"Extract features using ResNet.\"\"\"\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        resnet_features = resnet_model(input_tensor)\n",
    "    return resnet_features.flatten().numpy()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extract combined VGG, ResNet, and HOG features.\"\"\"\n",
    "    vgg_features = extract_intermediate_features(image, vgg_model, 'features')\n",
    "    resnet_features = extract_resnet_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "\n",
    "    # Assign different weights to each feature set\n",
    "    vgg_weight = 0.5\n",
    "    resnet_weight = 0.3\n",
    "    hog_weight = 0.2\n",
    "\n",
    "    # Combine all features with weights\n",
    "    combined_features = np.concatenate([\n",
    "        vgg_features * vgg_weight, \n",
    "        resnet_features * resnet_weight, \n",
    "        hog_features * hog_weight\n",
    "    ])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = image.resize((128, 128))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "\n",
    "    hog_features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(1, 1), visualize=False, feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    if features1.size == 0 or features2.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    features1 = features1.reshape(1, -1)\n",
    "    features2 = features2.reshape(1, -1)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((300, 300))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "def find_top_similar_pdfs(input_image_path, folder_path, top_n=10):\n",
    "    input_image = Image.open(input_image_path)\n",
    "\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "\n",
    "    pdf_similarity_scores = []\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                # Adjust the weighting of similarity and keypoints for better matching\n",
    "                combined_score = (0.7 * similarity + 0.3 * (keypoint_match_count / 1000))\n",
    "\n",
    "                pdf_similarity_scores.append((pdf_file, combined_score))\n",
    "\n",
    "    # Sort by similarity score in descending order and return the top N results\n",
    "    pdf_similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar_pdfs = pdf_similarity_scores[:top_n]\n",
    "\n",
    "    return top_similar_pdfs\n",
    "\n",
    "# Usage example\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//Capture3.jpg\"\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"\n",
    "\n",
    "top_similar_pdfs = find_top_similar_pdfs(input_image_path, folder_path)\n",
    "\n",
    "if top_similar_pdfs:\n",
    "    for pdf, score in top_similar_pdfs:\n",
    "        print(f\"PDF: {pdf} with similarity score: {score:.4f}\")\n",
    "else:\n",
    "    print(\"No similar images found in the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4b0a0-0cb8-4915-a18a-d20398db254e",
   "metadata": {},
   "source": [
    "This gives us top two similar lights based on the image search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566a910-73c6-4d94-9aa0-6f3ae4638f2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backbone 2: Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432bd817-b593-4a23-99c8-11f07f82690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Summary:\n",
      "Wattages: 20, 30, 40, 20, 18 W\n",
      "CCTs: 3500, 4000, 5000 K\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Only add text if extraction was successful\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "# Step 2: Clean the extracted text by removing unnecessary formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces/newlines with single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Step 3: Extract specific data (Lumens, Wattages, CCTs, Beam Angles) using regex\n",
    "def extract_lumens_wattage_cct_beam_angles(text):\n",
    "    # Patterns to match Lumens, Wattages, CCTs, and Beam Angles\n",
    "    lumens_pattern = r'\\b(\\d{3,5})\\s*Lumens?\\b'  # Matches 'XXX Lumens' or 'XXXXX Lumens'\n",
    "    wattage_pattern = r'\\b(\\d{1,3})\\s*W\\b'  # Matches 'X W', 'XX W', or 'XXX W'\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'  # Matches 'XXXX K' (CCT in Kelvin)\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'  # Matches 'XX' or 'XXX' for beam angle\n",
    "\n",
    "    # Extract data using regex\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    wattages = re.findall(wattage_pattern, text)\n",
    "    ccts = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    # Format extracted data into a dictionary\n",
    "    extracted_data = {\n",
    "        \"Lumens\": lumens,\n",
    "        \"Wattages\": wattages,\n",
    "        \"CCTs (K)\": ccts,\n",
    "        \"Beam Angles ()\": beam_angles\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Step 4: Summarize the extracted data\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])}\\n\"\n",
    "    \n",
    "    if extracted_data[\"Wattages\"]:\n",
    "        summary += f\"Wattages: {', '.join(extracted_data['Wattages'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCTs (K)\"]:\n",
    "        summary += f\"CCTs: {', '.join(extracted_data['CCTs (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angles: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Step 5: Execute the Pipeline to Read and Extract Relevant Data from the PDF\n",
    "pdf_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights//Delphi_PL_2x2FT_403020W_504035K_DLC_TDS.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Extract Lumens, Wattages, CCTs, and Beam Angles\n",
    "extracted_data = extract_lumens_wattage_cct_beam_angles(pdf_text)\n",
    "\n",
    "# Summarize the extracted data\n",
    "summary = summarize_extracted_data(extracted_data)\n",
    "\n",
    "print(f\"Extracted Summary:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a428b9-442e-4e05-aac2-47b219f9c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Summary:\n",
      "Power: 10, 7, 10, 7, 10, 10, 10, 15, 20, 20 W\n",
      "Voltage: 10, 10, 10, 277, 120, 277, 277, 347, 10, 10 V\n",
      "Lumens: 2000, 3200, 4000, 5000, 3200, 2000, 3200, 4000, 5000, 3200, 4000, 3000, 4000, 5000, 6000, 7200, 8500, 10000, 4000, 5000, 2000, 120\n",
      "CCT: 3000, 3500, 4000, 3500, 3500, 3500 K\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Only add text if extraction was successful\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "# Step 2: Clean the extracted text by removing unnecessary formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces/newlines with single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Step 3: Extract specific data (Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angle) using regex\n",
    "def extract_specifications(text):\n",
    "    # Patterns to match Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angles\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'  # Matches 'X W', 'XX W', or 'XXX W' for Power\n",
    "    voltage_pattern = r'\\b(\\d{1,3})\\s*V\\b'  # Matches 'XX V' or 'XXX V' for Voltage\n",
    "    current_pattern = r'\\b(\\d{1,3}\\.\\d{1,3})\\s*A\\b'  # Matches 'X.XX A' for Current\n",
    "    lumens_pattern = r'\\b(\\d{3,6})\\s*Lumens?\\b'  # Matches 'XXX Lumens' or 'XXXXX Lumens'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4})\\s*lm/W\\b'  # Matches 'XXX lm/W' for efficacy\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'  # Matches 'XXXX K' (CCT in Kelvin)\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'  # Matches 'XX' or 'XXX' for beam angle\n",
    "\n",
    "    # Extract data using regex\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    # Format extracted data into a dictionary\n",
    "    extracted_data = {\n",
    "        \"Power (W)\": power,\n",
    "        \"Voltage (V)\": voltage,\n",
    "        \"Current (A)\": current,\n",
    "        \"Lumens\": lumens,\n",
    "        \"Efficacy (lm/W)\": efficacy,\n",
    "        \"CCT (K)\": cct,\n",
    "        \"Beam Angles ()\": beam_angles\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Step 4: Summarize the extracted data\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])}\\n\"\n",
    "    \n",
    "    if extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angles: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Step 5: Execute the Pipeline to Read and Extract Relevant Data from the PDF\n",
    "pdf_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//configurable-cpx.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Extract Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angles\n",
    "extracted_data = extract_specifications(pdf_text)\n",
    "\n",
    "# Summarize the extracted data\n",
    "summary = summarize_extracted_data(extracted_data)\n",
    "\n",
    "print(f\"Extracted Summary:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5465a38-dcf8-480d-9915-46cf9b1710f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D://Cross Search Automation//Previous Cross//IKIO Lights//Area Luminaires//Areon_AL_Bronze_70W100W150_MV_TDS.pdf...\n",
      "Extracted Summary for D://Cross Search Automation//Previous Cross//IKIO Lights//Area Luminaires//Areon_AL_Bronze_70W100W150_MV_TDS.pdf:\n",
      "Ordering Part Number: IK-SBSLG2-150W-30/40/50K-MV-BR, IK-SBSLG2-150W-30/40/50K-MV-D\n",
      "Power: 22, 150 W\n",
      "Voltage: 100-277, 120-277, 480 V\n",
      "Current: 0.61 A\n",
      "Lumens: 482453 lm\n",
      "Efficacy: 133.98 lm/W\n",
      "CCT: 3000, 4000, 5000 K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Only add text if extraction was successful\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "# Step 2: Clean the extracted text by removing unnecessary formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces/newlines with single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Step 3: Extract specific data including Ordering Part Number, Power, Voltage, Current, etc.\n",
    "def extract_specifications(text):\n",
    "    # Patterns to match specifications\n",
    "    ordering_part_number_pattern = r'IK-[A-Z0-9-]+-[0-9]{2,4}W-[0-9/]+K-[A-Z]+-[A-Z]+'  # Ordering Part Number\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'  # Matches 'X W', 'XX W', or 'XXX W' for Power\n",
    "    voltage_pattern = r'(\\d{2,3})\\s*-\\s*(\\d{2,3})\\s*V|\\b(\\d{1,3})\\s*V\\b'  # Matches 'XX-XXX V' or 'XX V'\n",
    "    current_pattern = r'(\\d{1,3}\\.\\d{1,3})\\s*A'  # Matches 'X.XX A'\n",
    "    lumens_pattern = r'(\\d{3,6}(?:\\.\\d+)?)\\s*Lumens?\\b'  # Matches 'XXX Lumens' or 'XXXXX Lumens'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4}(?:\\.\\d+)?)\\s*lm/W\\b'  # Matches 'XXX lm/W' for efficacy\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'  # Matches 'XXXX K' (CCT in Kelvin)\n",
    "    beam_angle_pattern = r'(\\d{1,3})\\s*[]\\b'  # Matches 'XX' or 'XXX' for beam angle\n",
    "    finish_pattern = r'Finish:\\s*([A-Za-z0-9\\s]+)'  # Matches 'Finish: [value]'\n",
    "    warranty_pattern = r'Warranty:\\s*(\\d+)\\s*years?'  # Matches 'Warranty: X years'\n",
    "\n",
    "    # Extract data using regex\n",
    "    ordering_part_number = re.findall(ordering_part_number_pattern, text)\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "    finish = re.findall(finish_pattern, text)\n",
    "    warranty = re.findall(warranty_pattern, text)\n",
    "\n",
    "    # Process voltage to handle ranges (e.g., 120-277 V)\n",
    "    voltage_ranges = []\n",
    "    for volt in voltage:\n",
    "        if volt[0] and volt[1]:  # Handles '120-277 V' case\n",
    "            voltage_ranges.append(f\"{volt[0]}-{volt[1]}\")\n",
    "        elif volt[2]:  # Handles individual voltages like '277 V'\n",
    "            voltage_ranges.append(volt[2])\n",
    "\n",
    "    # Remove duplicates by converting lists to sets and then back to lists\n",
    "    extracted_data = {\n",
    "        \"Ordering Part Number\": sorted(set(ordering_part_number)),\n",
    "        \"Power (W)\": sorted(set(power), key=int),  # Sort numerically and remove duplicates\n",
    "        \"Voltage (V)\": sorted(set(voltage_ranges), key=lambda x: int(x.split('-')[0]) if '-' in x else int(x)),\n",
    "        \"Current (A)\": sorted(set(current), key=float),\n",
    "        \"Lumens\": sorted(set(lumens), key=float),  # Extract the numeric part from the tuples\n",
    "        \"Efficacy (lm/W)\": sorted(set(efficacy), key=float),\n",
    "        \"CCT (K)\": sorted(set(cct), key=int),\n",
    "        \"Beam Angles ()\": sorted(set(beam_angles), key=int),\n",
    "        \"Finish\": sorted(set(finish)),\n",
    "        \"Warranty\": sorted(set(warranty), key=lambda x: int(x))  # Sort warranty years numerically\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Step 4: Summarize the extracted data\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if \"Ordering Part Number\" in extracted_data and extracted_data[\"Ordering Part Number\"]:\n",
    "        summary += f\"Ordering Part Number: {', '.join(extracted_data['Ordering Part Number'])}\\n\"\n",
    "    \n",
    "    if \"Power (W)\" in extracted_data and extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if \"Voltage (V)\" in extracted_data and extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if \"Current (A)\" in extracted_data and extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if \"Lumens\" in extracted_data and extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])} lm\\n\"\n",
    "    \n",
    "    if \"Efficacy (lm/W)\" in extracted_data and extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if \"CCT (K)\" in extracted_data and extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if \"Beam Angles ()\" in extracted_data and extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angle: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    if \"Finish\" in extracted_data and extracted_data[\"Finish\"]:\n",
    "        summary += f\"Finish: {', '.join(extracted_data['Finish'])}\\n\"\n",
    "    \n",
    "    if \"Warranty\" in extracted_data and extracted_data[\"Warranty\"]:\n",
    "        summary += f\"Warranty: {', '.join(extracted_data['Warranty'])} years\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Step 5: Process a single PDF\n",
    "def process_single_pdf(pdf_path):\n",
    "    print(f\"Processing {pdf_path}...\")\n",
    "    \n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    extracted_data = extract_specifications(pdf_text)\n",
    "    summary = summarize_extracted_data(extracted_data)\n",
    "    \n",
    "    print(f\"Extracted Summary for {pdf_path}:\\n{summary}\\n\")\n",
    "\n",
    "# Step 6: Execute the pipeline for a single PDF\n",
    "pdf_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights//Area Luminaires//Areon_AL_Bronze_70W100W150_MV_TDS.pdf\"  # Update this to your file path\n",
    "process_single_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4fcf8-1410-4a86-a75f-f0295632779c",
   "metadata": {},
   "source": [
    "Now this is something that we can achieve for all the pdfs. I will now be implementing it for multiple pdf's and then converting it into a text similarity program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e9fd2e-205b-4cf2-afac-e6d4dc4d3b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing configurable-cpx.pdf...\n",
      "Extracted Summary for configurable-cpx.pdf:\n",
      "Power: 20, 15, 7, 10 W\n",
      "Voltage: 120-277, 347, 10, 277, 120 V\n",
      "Lumens: 2000, 10000, 4000, 7200, 3200, 5000, 3000, 120, 6000, 8500 lm\n",
      "CCT: 3000, 4000, 3500 K\n",
      "\n",
      "Processing lbk-configurable.pdf...\n",
      "Extracted Summary for lbk-configurable.pdf:\n",
      "Power: 3, 13, 77, 0, 1, 4, 5, 15, 20, 9, 10, 7, 2, 6, 51, 39, 26 W\n",
      "Voltage: 120-277, 347, 10 V\n",
      "Lumens: 120 lm\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Only add text if extraction was successful\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "# Step 2: Clean the extracted text by removing unnecessary formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces/newlines with single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Step 3: Extract specific data (Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angle) using regex\n",
    "def extract_specifications(text):\n",
    "    # Patterns to match Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angles\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'  # Matches 'X W', 'XX W', or 'XXX W' for Power\n",
    "    voltage_pattern = r'(\\d{2,3})\\s*-\\s*(\\d{2,3})\\s*V|\\b(\\d{1,3})\\s*V\\b'  # Matches 'XX-XXX V' or 'XX V'\n",
    "    current_pattern = r'(\\d{1,3}\\.\\d{1,3})\\s*A'  # Matches 'X.XX A'\n",
    "    lumens_pattern = r'(\\d{3,6}(\\.\\d+)?)\\s*Lumens?\\b'  # Matches 'XXX Lumens' or 'XXXXX Lumens'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4}\\.\\d+|\\d{2,4})\\s*lm/W\\b'  # Matches 'XXX lm/W' for efficacy\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'  # Matches 'XXXX K' (CCT in Kelvin)\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'  # Matches 'XX' or 'XXX' for beam angle\n",
    "\n",
    "    # Extract data using regex\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    # Process voltage to handle range (e.g., 120-277 V)\n",
    "    voltage_ranges = []\n",
    "    for volt in voltage:\n",
    "        if volt[0] and volt[1]:  # Handles '120-277 V' case\n",
    "            voltage_ranges.append(f\"{volt[0]}-{volt[1]}\")\n",
    "        elif volt[2]:  # Handles individual voltages like '277 V'\n",
    "            voltage_ranges.append(volt[2])\n",
    "\n",
    "    # Remove duplicates by converting lists to sets and then back to lists\n",
    "    extracted_data = {\n",
    "        \"Power (W)\": list(set(power)),\n",
    "        \"Voltage (V)\": list(set(voltage_ranges)),\n",
    "        \"Current (A)\": list(set(current)),\n",
    "        \"Lumens\": list(set([lum[0] for lum in lumens])),  # Extract the numeric part from tuples\n",
    "        \"Efficacy (lm/W)\": list(set(efficacy)),\n",
    "        \"CCT (K)\": list(set(cct)),\n",
    "        \"Beam Angles ()\": list(set(beam_angles))\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Step 4: Summarize the extracted data\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])} lm\\n\"\n",
    "    \n",
    "    if extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angle: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Step 5: Process multiple PDFs in the folder\n",
    "def process_pdfs_in_folder(folder_path):\n",
    "    # Get all PDF files in the folder\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    # Loop through each PDF and extract information\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        print(f\"Processing {pdf_file}...\")\n",
    "        \n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        extracted_data = extract_specifications(pdf_text)\n",
    "        summary = summarize_extracted_data(extracted_data)\n",
    "        \n",
    "        print(f\"Extracted Summary for {pdf_file}:\\n{summary}\\n\")\n",
    "\n",
    "# Step 6: Execute the pipeline for all PDFs in a folder\n",
    "folder_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights\"  # Update this to your folder path\n",
    "process_pdfs_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b5904-8ebd-481b-9559-c26d1b3a18c8",
   "metadata": {},
   "source": [
    "Now I am converting the above code to do the same for IKIO Lights folder and Vendor Lights folder and provide the results for all the pdf's in the same format. Which will act as a backbone for the next step which would be comparing and finding similarity aongst the pdf's of the two folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3f08b2-e7df-4bb9-9068-da60da6db335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs from IKIO Lights folder:\n",
      "\n",
      "Processing 1 strip Aimant_MRSK_24W_4000K_120-277V_PC_lens_1strip_TDS.pdf...\n",
      "Extracted Summary for 1 strip Aimant_MRSK_24W_4000K_120-277V_PC_lens_1strip_TDS.pdf:\n",
      "Power: 24, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.10 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing 1 strip Aimant_MRSK_24W_5000K_120-277V_PC_lens_1strip_TDS.pdf...\n",
      "Extracted Summary for 1 strip Aimant_MRSK_24W_5000K_120-277V_PC_lens_1strip_TDS.pdf:\n",
      "Power: 24, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.10 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Ace_CB_36W45W54W_TDS.pdf...\n",
      "Extracted Summary for Ace_CB_36W45W54W_TDS.pdf:\n",
      "Power: 54 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.22 A\n",
      "Lumens: 482439 lm\n",
      "Efficacy: 135.35 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Ace_CB_80W100W120W_TDS.pdf...\n",
      "Extracted Summary for Ace_CB_80W100W120W_TDS.pdf:\n",
      "Power: 120, 33 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.22 A\n",
      "Efficacy: 134.33 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_24W_4000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_24W_4000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 24, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.10 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_24W_5000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_24W_5000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 24, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.10 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_30W_4000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_30W_4000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 30, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.12 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_30W_5000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_30W_5000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 30, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.12 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_40W_4000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_40W_4000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 40, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.16 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Aimant_MRSK_40W_5000K_120-277V_PC_lens_2strip_TDS.pdf...\n",
      "Extracted Summary for Aimant_MRSK_40W_5000K_120-277V_PC_lens_2strip_TDS.pdf:\n",
      "Power: 40, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.16 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_Gen2_LHB_100W150W200W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for Amplin_Gen2_LHB_100W150W200W_5000K_MV_TDS.pdf:\n",
      "Power: 150, 18, 200, 100, 10 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.77, 0.57, 0.38 A\n",
      "Efficacy: 141.02, 148.16, 146.16 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_Gen2_LHB_200W240W300W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for Amplin_Gen2_LHB_200W240W300W_5000K_MV_TDS.pdf:\n",
      "Power: 18, 200, 10, 300, 240 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.12, 0.74, 0.89 A\n",
      "Efficacy: 141.02, 148.11, 147.04 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_100W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_100W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 2, 18, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Current: 0.39 A\n",
      "Lumens: 477978 lm\n",
      "Efficacy: 145.54 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_150W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_150W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 18, 8, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Current: 8.37, 0.57 A\n",
      "Lumens: 477985 lm\n",
      "Efficacy: 148.9 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_200W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_200W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 18, 7, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Current: 0.78 A\n",
      "Lumens: 478005 lm\n",
      "Efficacy: 147.1 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_240W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_240W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 18, 3, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Current: 0.90 A\n",
      "Lumens: 478012 lm\n",
      "Efficacy: 143.43 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_300W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_300W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 18, 5, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Current: 1.14 A\n",
      "Lumens: 478029 lm\n",
      "Efficacy: 147.24 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Amplin_LHB_White_75W_5000K_100-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Amplin_LHB_White_75W_5000K_100-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 18, 85, 10 W\n",
      "Voltage: 480, 10, 100-277, 200 V\n",
      "Lumens: 544380 lm\n",
      "Efficacy: 142.38 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Apex_LLB_Without_Sensor_50W60W70W_TDS.pdf...\n",
      "Extracted Summary for Apex_LLB_Without_Sensor_50W60W70W_TDS.pdf:\n",
      "Power: 8, 70, 4 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.29 A\n",
      "Lumens: 482781 lm\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Apex_LLB_With_Sensor_50W60W70W_TDS.pdf...\n",
      "Extracted Summary for Apex_LLB_With_Sensor_50W60W70W_TDS.pdf:\n",
      "Power: 8, 70, 4 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.29 A\n",
      "Efficacy: 139.87 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_Bronze_150W200W240W300W_HV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_Bronze_150W200W240W300W_HV_TDS.pdf:\n",
      "Power: 300, 27 W\n",
      "Voltage: 480, 277-480 V\n",
      "Current: 1.23 A\n",
      "Efficacy: 131.96 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_Bronze_150W200W240W300W_MV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_Bronze_150W200W240W300W_MV_TDS.pdf:\n",
      "Power: 300, 93 W\n",
      "Voltage: 480, 100-277 V\n",
      "Current: 1.23 A\n",
      "Efficacy: 129.59 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_Bronze_70W100W150_MV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_Bronze_70W100W150_MV_TDS.pdf:\n",
      "Power: 150, 22 W\n",
      "Voltage: 120-277, 480, 100-277 V\n",
      "Current: 0.61 A\n",
      "Lumens: 482453 lm\n",
      "Efficacy: 133.98 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_White_150W200W240W300W_HV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_White_150W200W240W300W_HV_TDS.pdf:\n",
      "Power: 300, 27 W\n",
      "Voltage: 480, 277-480 V\n",
      "Current: 1.23 A\n",
      "Efficacy: 131.96 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_White_150W200W240W300W_MV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_White_150W200W240W300W_MV_TDS.pdf:\n",
      "Power: 300, 93 W\n",
      "Voltage: 480, 100-277 V\n",
      "Current: 1.23, 20.94 A\n",
      "Efficacy: 129.59 lm/W\n",
      "CCT: 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Areon_AL_White_70W100W150_MV_TDS.pdf...\n",
      "Extracted Summary for Areon_AL_White_70W100W150_MV_TDS.pdf:\n",
      "Power: 150, 22 W\n",
      "Voltage: 120-277, 480, 100-277 V\n",
      "Current: 0.61 A\n",
      "Lumens: 482460 lm\n",
      "Efficacy: 133.98 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Canolux_GSCL_100W120W150W_TDS.pdf...\n",
      "Extracted Summary for Canolux_GSCL_100W120W150W_TDS.pdf:\n",
      "Power: 150, 120, 151, 100 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.57 A\n",
      "Efficacy: 146, 146.33 lm/W\n",
      "CCT: 5700, 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Coloris_RGBW_ELPL_1'x4'_36W_TDS.pdf...\n",
      "Extracted Summary for Coloris_RGBW_ELPL_1'x4'_36W_TDS.pdf:\n",
      "Power: 36, 18, 10 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.40 A\n",
      "Efficacy: 130 lm/W\n",
      "\n",
      "\n",
      "Processing Coloris_RGBW_ELPL_2'x2'_36W_TDS.pdf...\n",
      "Extracted Summary for Coloris_RGBW_ELPL_2'x2'_36W_TDS.pdf:\n",
      "Power: 36, 18, 10 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.40 A\n",
      "Efficacy: 130 lm/W\n",
      "\n",
      "\n",
      "Processing Coloris_RGBW_ELPL_2'x4'_60W_TDS.pdf...\n",
      "Extracted Summary for Coloris_RGBW_ELPL_2'x4'_60W_TDS.pdf:\n",
      "Power: 18, 10, 60 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.67 A\n",
      "Efficacy: 130 lm/W\n",
      "\n",
      "\n",
      "Processing Coloris_RGBW_ELPL_PS.pdf...\n",
      "Extracted Summary for Coloris_RGBW_ELPL_PS.pdf:\n",
      "Power: 36, 18, 10, 60 W\n",
      "Voltage: 100-277 V\n",
      "Efficacy: 130 lm/W\n",
      "\n",
      "\n",
      "Processing Conall Linear Area Lights.pdf...\n",
      "Extracted Summary for Conall Linear Area Lights.pdf:\n",
      "Power: 40, 30, 50, 20, 60 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.20, 0.12, 0.24, 0.16, 0.08 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_AT(F)_1x4_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_AT(F)_1x4_DLC_TDS.pdf:\n",
      "Power: 25, 30, 20, 18 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.12, 0.08, 0.10 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_AT(F)_2x2_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_AT(F)_2x2_DLC_TDS.pdf:\n",
      "Power: 25, 30, 20, 18 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.12 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_AT(F)_2x4_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_AT(F)_2x4_DLC_TDS.pdf:\n",
      "Power: 18, 30, 25, 35 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.14 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_BLPL_PS.pdf...\n",
      "Extracted Summary for Delphi_BLPL_PS.pdf:\n",
      "Power: 150, 18, 30, 100, 20 W\n",
      "Voltage: 120-277, 10 V\n",
      "\n",
      "\n",
      "Processing Delphi_FPCL_PS.pdf...\n",
      "Extracted Summary for Delphi_FPCL_PS.pdf:\n",
      "Power: 400, 300, 8 W\n",
      "Voltage: 120-277, 120-347, 10 V\n",
      "Efficacy: 123.21 lm/W\n",
      "\n",
      "\n",
      "Processing Delphi_FPCN_30W-40W-49.8W_120-347V_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_FPCN_30W-40W-49.8W_120-347V_DLC_TDS.pdf:\n",
      "Power: 40, 30, 0050, 8 W\n",
      "Voltage: 120-347, 10 V\n",
      "Current: 0.10, 0.13, 0.16 A\n",
      "Efficacy: 123.21 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_LLB_2'_TDS.pdf...\n",
      "Extracted Summary for Delphi_LLB_2'_TDS.pdf:\n",
      "Power: 18, 22, 25 W\n",
      "Voltage: 120-347 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 127 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_LLB_4'_TDS.pdf...\n",
      "Extracted Summary for Delphi_LLB_4'_TDS.pdf:\n",
      "Power: 36, 40, 50 W\n",
      "Voltage: 120-347 V\n",
      "Current: 0.16 A\n",
      "Efficacy: 127 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_Mini_WP_PS.pdf...\n",
      "Extracted Summary for Delphi_Mini_WP_PS.pdf:\n",
      "Power: 4, 100 W\n",
      "Voltage: 120-277, 10 V\n",
      "\n",
      "\n",
      "Processing Delphi_Mini_WP_TDS.pdf...\n",
      "Extracted Summary for Delphi_Mini_WP_TDS.pdf:\n",
      "Power: 25, 20, 15, 4 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.06, 0.08, 0.10 A\n",
      "Efficacy: 131.67 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_PL_1x4FT_403020W_504035K_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_PL_1x4FT_403020W_504035K_DLC_TDS.pdf:\n",
      "Power: 18, 40, 30, 20 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.12, 0.08, 5.73, 0.16 A\n",
      "Efficacy: 125 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_PL_2x2FT_403020W_504035K_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_PL_2x2FT_403020W_504035K_DLC_TDS.pdf:\n",
      "Power: 18, 40, 30, 20 W\n",
      "Voltage: 120-277 V\n",
      "Current: 5.11, 0.15, 0.08, 0.11 A\n",
      "Efficacy: 133.74 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_PL_2x4FT_504030W_504035K_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_PL_2x4FT_504030W_504035K_DLC_TDS.pdf:\n",
      "Power: 18, 40, 30, 50 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.18, 0.15, 9.6, 0.11 A\n",
      "Efficacy: 130.38 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_RT(F)_1x4_TDS.pdf...\n",
      "Extracted Summary for Delphi_RT(F)_1x4_TDS.pdf:\n",
      "Power: 25, 30, 20, 18 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.09, 0.08, 0.11 A\n",
      "Efficacy: 127 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_RT(F)_2x2_TDS.pdf...\n",
      "Extracted Summary for Delphi_RT(F)_2x2_TDS.pdf:\n",
      "Power: 25, 30, 20, 18 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.07, 0.09, 0.11 A\n",
      "Efficacy: 124 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_RT(F)_2x4_TDS.pdf...\n",
      "Extracted Summary for Delphi_RT(F)_2x4_TDS.pdf:\n",
      "Power: 18, 30, 25, 35 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.09, 0.13, 0.11 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Delphi_WP_FC_40W60W80W100W_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_WP_FC_40W60W80W100W_DLC_TDS.pdf:\n",
      "Power: 40, 100, 80, 4, 60 W\n",
      "Voltage: 120-347 V\n",
      "Current: 0.30 A\n",
      "Efficacy: 123.21 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_WP_SC_21W28W34.98W_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_WP_SC_21W28W34.98W_DLC_TDS.pdf:\n",
      "Power: 21, 98, 35, 28 W\n",
      "Voltage: 120-347 V\n",
      "Current: 0.07, 0.09, 0.11 A\n",
      "Efficacy: 125.41 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_WP_SC_30W42W50.67W_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_WP_SC_30W42W50.67W_DLC_TDS.pdf:\n",
      "Power: 42, 30, 50, 67 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.16, 0.19, 0.11 A\n",
      "Efficacy: 131.17 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Delphi_WP_SC_72W100W114.8W_DLC_TDS.pdf...\n",
      "Extracted Summary for Delphi_WP_SC_72W100W114.8W_DLC_TDS.pdf:\n",
      "Power: 120, 72, 8, 100 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.42, 0.37, 0.27 A\n",
      "Efficacy: 126.52 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Dominus Explosion Proof Square High Bay.pdf...\n",
      "Extracted Summary for Dominus Explosion Proof Square High Bay.pdf:\n",
      "Power: 150, 100, 200, 80, 20, 60, 120 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 0.80, 0.48, 0.24, 0.40, 0.32, 0.60, 0.08 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_300W_3000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_300W_3000K_100-277V_TDS.pdf:\n",
      "Power: 300 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.08 A\n",
      "Lumens: 461571 lm\n",
      "Efficacy: 146.9 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_300W_4000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_300W_4000K_100-277V_TDS.pdf:\n",
      "Power: 300 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 154.2 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_300W_4000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_300W_4000K_277-480V_TDS.pdf:\n",
      "Power: 300 W\n",
      "Voltage: 277-480 V\n",
      "Current: 0.63 A\n",
      "Efficacy: 157.1 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_300W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_300W_5000K_100-277V_TDS.pdf:\n",
      "Power: 300 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 161.2 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_300W_5000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_300W_5000K_277-480V_TDS.pdf:\n",
      "Power: 300 W\n",
      "Voltage: 277-480 V\n",
      "Current: 0.63 A\n",
      "Efficacy: 163.1 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_3000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_3000K_100-277V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.45 A\n",
      "Efficacy: 153.6 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_3000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_3000K_277-480V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 277-480 V\n",
      "Current: 0.84 A\n",
      "Efficacy: 153.8 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_4000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_4000K_100-277V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.45 A\n",
      "Efficacy: 155.7 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_4000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_4000K_277-480V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 277-480 V\n",
      "Current: 0.84 A\n",
      "Efficacy: 156.4 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_5000K_100-277V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.45 A\n",
      "Efficacy: 158 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_400W_5000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_400W_5000K_277-480V_TDS.pdf:\n",
      "Power: 400 W\n",
      "Voltage: 277-480 V\n",
      "Current: 0.84 A\n",
      "Efficacy: 158.7 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_3000K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_3000K_100-277V_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Lumens: 528465 lm\n",
      "Efficacy: 150.2 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_3000K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_3000K_277-480V_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 150.7 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_3500K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_3500K_100-277V_DLC_TDS.pdf:\n",
      "Power: 6 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Efficacy: 151.4 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_3500K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_3500K_277-480V_DLC_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 152.2 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_4000K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_4000K_100-277V_DLC_TDS.pdf:\n",
      "Power: 6 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Efficacy: 152.4 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_4000K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_4000K_277-480V_DLC_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 153.6 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_4500K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_4500K_100-277V_DLC_TDS.pdf:\n",
      "Power: 6 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Efficacy: 153.4 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_4500K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_4500K_277-480V_DLC_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 154.9 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_5000K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_5000K_100-277V_DLC_TDS.pdf:\n",
      "Power: 6 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Efficacy: 154.4 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_5000K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_5000K_277-480V_DLC_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 156.3 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_5700K_100-277V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_5700K_100-277V_DLC_TDS.pdf:\n",
      "Power: 495 W\n",
      "Voltage: 100-277 V\n",
      "Current: 1.88 A\n",
      "Efficacy: 155.6 lm/W\n",
      "CCT: 5700 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_500W_5700K_277-480V_DLC_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_500W_5700K_277-480V_DLC_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.08 A\n",
      "Efficacy: 157.8 lm/W\n",
      "CCT: 5700 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_3000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_3000K_100-277V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 100-277 V\n",
      "Current: 2.17 A\n",
      "Efficacy: 140.9 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_3000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_3000K_277-480V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.25 A\n",
      "Efficacy: 145.8 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_4000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_4000K_100-277V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 100-277 V\n",
      "Current: 2.17 A\n",
      "Efficacy: 143.1 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_4000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_4000K_277-480V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.25 A\n",
      "Efficacy: 148.1 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_5000K_100-277V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 100-277 V\n",
      "Current: 2.17 A\n",
      "Efficacy: 145.4 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Dynamo3_SFL_600W_5000K_277-480V_TDS.pdf...\n",
      "Extracted Summary for Dynamo3_SFL_600W_5000K_277-480V_TDS.pdf:\n",
      "Power: 600 W\n",
      "Voltage: 277-480 V\n",
      "Current: 1.25 A\n",
      "Efficacy: 150.4 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Edin_WP_SC_30W40W50W60W_30K40K50K_TDS.pdf...\n",
      "Extracted Summary for Edin_WP_SC_30W40W50W60W_30K40K50K_TDS.pdf:\n",
      "Power: 7 W\n",
      "Voltage: 120-277, 100-277, 10 V\n",
      "Current: 0.25 A\n",
      "Efficacy: 139.81 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Edin_WP_SC_70W85W100W120W_30K40K50K_TDS.pdf...\n",
      "Extracted Summary for Edin_WP_SC_70W85W100W120W_30K40K50K_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 120-277, 100-277, 10 V\n",
      "Current: 0.50 A\n",
      "Efficacy: 138.74 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Ergo Explosion Proof Linear High Bay.pdf...\n",
      "Extracted Summary for Ergo Explosion Proof Linear High Bay.pdf:\n",
      "Power: 100, 80, 20, 60, 120 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 0.48, 0.24, 0.40, 0.32, 0.08 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Exoplus Explosion Proof Round High Bay.pdf...\n",
      "Extracted Summary for Exoplus Explosion Proof Round High Bay.pdf:\n",
      "Power: 150, 100, 200, 80, 280, 20, 60 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 1.12, 0.80, 0.24, 0.40, 0.32, 0.60, 0.08 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Forza Explosion Proof Square High Bay.pdf...\n",
      "Extracted Summary for Forza Explosion Proof Square High Bay.pdf:\n",
      "Power: 150, 40, 400, 100, 200, 250, 80, 20, 60 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 0.80, 0.24, 0.40, 0.32, 0.16, 1.00, 0.50, 0.08, 1.60 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Frizo_RFL_3FT_13W_4000K_DN_100-277V_CL_TDS.pdf...\n",
      "Extracted Summary for Frizo_RFL_3FT_13W_4000K_DN_100-277V_CL_TDS.pdf:\n",
      "Power: 13 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.14 A\n",
      "Efficacy: 125 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Frizo_RFL_4FT_18W_4000K_DN_100-277V_CR_TDS.pdf...\n",
      "Extracted Summary for Frizo_RFL_4FT_18W_4000K_DN_100-277V_CR_TDS.pdf:\n",
      "Power: 18 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.20 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Frizo_RFL_4FT_18W_5000K_DN_100-277V_CR_TDS.pdf...\n",
      "Extracted Summary for Frizo_RFL_4FT_18W_5000K_DN_100-277V_CR_TDS.pdf:\n",
      "Power: 18 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.20 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Frizo_RFL_6FT_30W_4000K_DY_100-277V_CR_TDS.pdf...\n",
      "Extracted Summary for Frizo_RFL_6FT_30W_4000K_DY_100-277V_CR_TDS.pdf:\n",
      "Power: 30 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.33 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Frizo_RFL_6FT_30W_5000K_DY_100-277V_CR_TDS.pdf...\n",
      "Extracted Summary for Frizo_RFL_6FT_30W_5000K_DY_100-277V_CR_TDS.pdf:\n",
      "Power: 30 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.33 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_297.2W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_297.2W_5000K_HV_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 0.69 A\n",
      "Lumens: 485423 lm\n",
      "CCT: 5700, 5000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_297.4W_5700K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_297.4W_5700K_HV_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 0.69 A\n",
      "CCT: 5700, 5000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_297W_4000K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_297W_4000K_HV_TDS.pdf:\n",
      "Power: 297 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 0.69 A\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_450W575W595.9W_4000K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_450W575W595.9W_4000K_HV_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 2.39 A\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_450W575W595.9W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_450W575W595.9W_5000K_HV_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 2.39 A\n",
      "Efficacy: 150.35 lm/W\n",
      "CCT: 5700, 5000 K\n",
      "\n",
      "\n",
      "Processing Hexacule_HML_450W575W595.9W_5700K_HV_TDS.pdf...\n",
      "Extracted Summary for Hexacule_HML_450W575W595.9W_5700K_HV_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 2.39 A\n",
      "Efficacy: 69 lm/W\n",
      "CCT: 5700, 5000 K\n",
      "\n",
      "\n",
      "Processing Jarrex Explosion Proof Jelly Jar Light.pdf...\n",
      "Extracted Summary for Jarrex Explosion Proof Jelly Jar Light.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.12, 0.08, 0.16 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Lantorch Drop Light.pdf...\n",
      "Extracted Summary for Lantorch Drop Light.pdf:\n",
      "Power: 30, 20 W\n",
      "Voltage: 100-277 V\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Lineo_LHB_80W110W135W165W_TDS.pdf...\n",
      "Extracted Summary for Lineo_LHB_80W110W135W165W_TDS.pdf:\n",
      "Power: 165, 5, 16 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.64 A\n",
      "Lumens: 482354 lm\n",
      "Efficacy: 141.65, 141 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Lior_LHB_200W240W320W400W_TDS.pdf...\n",
      "Extracted Summary for Lior_LHB_200W240W320W400W_TDS.pdf:\n",
      "Power: 400, 200, 16, 320, 240 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.80, 15.43, 1.60, 0.96, 1.28 A\n",
      "Lumens: 487021 lm\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Lior_LHB_220W295W320W_TDS.pdf...\n",
      "Extracted Summary for Lior_LHB_220W295W320W_TDS.pdf:\n",
      "Power: 16, 320, 7 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 1.29 A\n",
      "Lumens: 540382 lm\n",
      "Efficacy: 139.53 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Lior_LHB_400W500W600W_TDS.pdf...\n",
      "Extracted Summary for Lior_LHB_400W500W600W_TDS.pdf:\n",
      "Power: 400, 16, 500, 600 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 2.01, 2.41, 1.60 A\n",
      "Lumens: 540375 lm\n",
      "Efficacy: 140.62, 138.38, 147.27 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Lior_LHB_Without_Sensor_110W130W160W_TDS.pdf...\n",
      "Extracted Summary for Lior_LHB_Without_Sensor_110W130W160W_TDS.pdf:\n",
      "Power: 130, 160, 16, 110 W\n",
      "Voltage: 277-480, 10 V\n",
      "Current: 0.30, 6.82, 0.37, 0.25 A\n",
      "Efficacy: 154 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_Bronze_200W240W300W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_Bronze_200W240W300W_5000K_HV_TDS.pdf:\n",
      "Power: 300, 7 W\n",
      "Voltage: 277-480, 200-480, 90-480 V\n",
      "Current: 0.65 A\n",
      "Efficacy: 165.1 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_Bronze_200W240W300W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_Bronze_200W240W300W_5000K_MV_TDS.pdf:\n",
      "Power: 300, 5 W\n",
      "Voltage: 90-480, 90-277, 100-277 V\n",
      "Current: 0.65 A\n",
      "Efficacy: 161.2 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_Bronze_75W100W150W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_Bronze_75W100W150W_5000K_HV_TDS.pdf:\n",
      "Power: 150, 8 W\n",
      "Voltage: 277-480, 200-480, 90-480 V\n",
      "Current: 0.32 A\n",
      "Efficacy: 162.7 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_Bronze_75W100W150W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_Bronze_75W100W150W_5000K_MV_TDS.pdf:\n",
      "Power: 150, 4 W\n",
      "Voltage: 90-480, 90-277, 100-277 V\n",
      "Current: 0.56 A\n",
      "Efficacy: 158.7 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_White_200W240W300W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_White_200W240W300W_5000K_HV_TDS.pdf:\n",
      "Power: 300, 7 W\n",
      "Voltage: 277-480, 200-480, 90-480 V\n",
      "Current: 0.65 A\n",
      "Efficacy: 165.1 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_White_200W240W300W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_White_200W240W300W_5000K_MV_TDS.pdf:\n",
      "Power: 300, 5 W\n",
      "Voltage: 90-480, 90-277, 100-277 V\n",
      "Current: 0.65 A\n",
      "Efficacy: 161.2 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_White_75W100W150W_5000K_HV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_White_75W100W150W_5000K_HV_TDS.pdf:\n",
      "Power: 150, 8 W\n",
      "Voltage: 277-480, 200-480, 90-480 V\n",
      "Current: 0.32 A\n",
      "Efficacy: 162.7 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing LocusGen2_AL_White_75W100W150W_5000K_MV_TDS.pdf...\n",
      "Extracted Summary for LocusGen2_AL_White_75W100W150W_5000K_MV_TDS.pdf:\n",
      "Power: 150, 4 W\n",
      "Voltage: 90-480, 90-277, 100-277 V\n",
      "Current: 0.56 A\n",
      "Efficacy: 158.7 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_100W_3000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_100W_3000K_100-277V_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.35 A\n",
      "Efficacy: 141.44 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_100W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_100W_5000K_100-277V_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.35 A\n",
      "Efficacy: 141.44 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_150W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_150W_5000K_100-277V_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.53 A\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_185W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_185W_5000K_100-277V_TDS.pdf:\n",
      "Power: 7 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.64 A\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_200W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_200W_5000K_100-277V_TDS.pdf:\n",
      "Power: 195 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.72 A\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_240W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_240W_5000K_100-277V_TDS.pdf:\n",
      "Power: 230 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.86 A\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_Bronze_300W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_Bronze_300W_5000K_100-277V_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 1.09 A\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_100W_3000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_100W_3000K_100-277V_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.35 A\n",
      "Efficacy: 141.44 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_100W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_100W_5000K_100-277V_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.35 A\n",
      "Efficacy: 141.44 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_150W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_150W_5000K_100-277V_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.53 A\n",
      "Efficacy: 141.18 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_185W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_185W_5000K_100-277V_TDS.pdf:\n",
      "Power: 7 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.64 A\n",
      "Efficacy: 137.58 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_200W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_200W_5000K_100-277V_TDS.pdf:\n",
      "Power: 195 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 0.72 A\n",
      "Efficacy: 143.01 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Locus_AL_White_300W_5000K_100-277V_TDS.pdf...\n",
      "Extracted Summary for Locus_AL_White_300W_5000K_100-277V_TDS.pdf:\n",
      "Power: 5 W\n",
      "Voltage: 010, 90-277, 00-480, 100-277, 200-480, 90-480 V\n",
      "Current: 1.09 A\n",
      "Efficacy: 141.66 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Magnus_AFL_100W150W205W_TDS.pdf...\n",
      "Extracted Summary for Magnus_AFL_100W150W205W_TDS.pdf:\n",
      "Power: 205, 54 W\n",
      "Voltage: 120-277, 100-277 V\n",
      "Current: 0.85 A\n",
      "Lumens: 482187 lm\n",
      "Efficacy: 133.94 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing main.pdf...\n",
      "Extracted Summary for main.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 120-277 V\n",
      "\n",
      "\n",
      "Processing Maxton_YL_30W40W50W60W_TDS.pdf...\n",
      "Extracted Summary for Maxton_YL_30W40W50W60W_TDS.pdf:\n",
      "Power: 74, 60 W\n",
      "Voltage: 120-277, 100-277 V\n",
      "Current: 0.24, 5.51 A\n",
      "Lumens: 482248 lm\n",
      "Efficacy: 142.35 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Neron Area Lights (1).pdf...\n",
      "Extracted Summary for Neron Area Lights (1).pdf:\n",
      "Power: 150, 240, 200, 100 W\n",
      "Voltage: 100-305 V\n",
      "Current: 0.80, 0.96, 0.60, 0.40 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Nevo_VTL_2FT_15W20W25W_30K40K50K_TDS.pdf...\n",
      "Extracted Summary for Nevo_VTL_2FT_15W20W25W_30K40K50K_TDS.pdf:\n",
      "Power: 25, 20, 15, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.06, 0.08, 0.10 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Nevo_VTL_4FT_20W30W40W_30K40K50K_TDS.pdf...\n",
      "Extracted Summary for Nevo_VTL_4FT_20W30W40W_30K40K50K_TDS.pdf:\n",
      "Power: 40, 30, 20, 8 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.12, 0.08, 0.16 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Novus_FL_TDS.pdf...\n",
      "Extracted Summary for Novus_FL_TDS.pdf:\n",
      "Power: 55 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.22 A\n",
      "Lumens: 478876 lm\n",
      "Efficacy: 125 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Orwin_DL_10inch_TDS.pdf...\n",
      "Extracted Summary for Orwin_DL_10inch_TDS.pdf:\n",
      "Power: 38, 22, 30, 18 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.14 A\n",
      "Efficacy: 93.83, 91.50, 89.11 lm/W\n",
      "CCT: 2700, 4000, 5000, 3000, 3500 K\n",
      "\n",
      "\n",
      "Processing Orwin_DL_6inch_TDS.pdf...\n",
      "Extracted Summary for Orwin_DL_6inch_TDS.pdf:\n",
      "Power: 18, 22, 17, 12 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 84.68, 87.50, 90.24 lm/W\n",
      "CCT: 2700, 4000, 5000, 3000, 3500 K\n",
      "\n",
      "\n",
      "Processing Orwin_DL_8inch_TDS.pdf...\n",
      "Extracted Summary for Orwin_DL_8inch_TDS.pdf:\n",
      "Power: 18, 30, 24, 17 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.11 A\n",
      "Efficacy: 90, 95, 95.64 lm/W\n",
      "CCT: 5000, 3000, 4000 K\n",
      "\n",
      "\n",
      "Processing Orwin_DL_PS.pdf...\n",
      "Extracted Summary for Orwin_DL_PS.pdf:\n",
      "Power: 150, 18, 30, 38, 100, 22, 120 W\n",
      "Voltage: 120-277, 10 V\n",
      "\n",
      "\n",
      "Processing Ove_Emergency_Mini_WP_13.4W_35K40K50K_TDS.pdf...\n",
      "Extracted Summary for Ove_Emergency_Mini_WP_13.4W_35K40K50K_TDS.pdf:\n",
      "Power: 5, 4 W\n",
      "Voltage: 120-277, 7, 10 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 130.34 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Rodella_UFO_Black_150W_3500K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Rodella_UFO_Black_150W_3500K_100-277 V_TDS.pdf:\n",
      "Power: 18, 8, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 1.24 A\n",
      "Efficacy: 141.06 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing Rodella_UFO_Black_150W_4000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Rodella_UFO_Black_150W_4000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 8, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 1.24 A\n",
      "Efficacy: 141.06 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Rodella_UFO_Black_240W_5000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Rodella_UFO_Black_240W_5000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 1, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 1.97 A\n",
      "Efficacy: 142.92 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing SigmaGen2_T8_EM1_Tube_Type_B_15W_3500K4000K5000K_TDS.pdf...\n",
      "Extracted Summary for SigmaGen2_T8_EM1_Tube_Type_B_15W_3500K4000K5000K_TDS.pdf:\n",
      "Power: 5, 15 W\n",
      "Voltage: 120-277, 6 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 146.7 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Sigma_EMTUBE_TypeB_PS.pdf...\n",
      "Extracted Summary for Sigma_EMTUBE_TypeB_PS.pdf:\n",
      "Power: 15, 32 W\n",
      "Voltage: 120-277 V\n",
      "Efficacy: 147, 146.67 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Sigma_EMTUBE_TypeB_White_15W_4000K_120-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Sigma_EMTUBE_TypeB_White_15W_4000K_120-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 5, 15 W\n",
      "Voltage: 120-277, 16 V\n",
      "Current: 1.10, 0.05 A\n",
      "Efficacy: 147, 140 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Sigma_EMTUBE_TypeB_White_15W_5000K_120-277V_Dimmable_DLC_TDS.pdf...\n",
      "Extracted Summary for Sigma_EMTUBE_TypeB_White_15W_5000K_120-277V_Dimmable_DLC_TDS.pdf:\n",
      "Power: 5, 15 W\n",
      "Voltage: 120-277, 16 V\n",
      "Current: 0.05 A\n",
      "Lumens: 539966 lm\n",
      "Efficacy: 147, 146.67 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Simplex_LLB_4'_40W_4000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Simplex_LLB_4'_40W_4000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 40, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.44 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Simplex_LLB_4'_40W_5000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Simplex_LLB_4'_40W_5000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 40, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.44 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Simplex_LLB_8'_60W_4000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Simplex_LLB_8'_60W_4000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 10, 60 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.67 A\n",
      "Efficacy: 138 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Simplex_LLB_8'_60W_5000K_100-277 V_TDS.pdf...\n",
      "Extracted Summary for Simplex_LLB_8'_60W_5000K_100-277 V_TDS.pdf:\n",
      "Power: 18, 10, 60 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.67 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Smart_Toucan_AT_IOS_25W_2'x2'_4000K_DLC_TDS.pdf...\n",
      "Extracted Summary for Smart_Toucan_AT_IOS_25W_2'x2'_4000K_DLC_TDS.pdf:\n",
      "Power: 55 W\n",
      "Voltage: 120-277, 10 V\n",
      "Lumens: 547084 lm\n",
      "Efficacy: 125.6 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Smart_Toucan_AT_IOS_25W_2'x2'_5000K_DLC_TDS.pdf...\n",
      "Extracted Summary for Smart_Toucan_AT_IOS_25W_2'x2'_5000K_DLC_TDS.pdf:\n",
      "Power: 62 W\n",
      "Voltage: 120-277, 10 V\n",
      "Efficacy: 131.4 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Smart_Toucan_AT_IOS_36W_2'x4'_4000K_DLC_TDS.pdf...\n",
      "Extracted Summary for Smart_Toucan_AT_IOS_36W_2'x4'_4000K_DLC_TDS.pdf:\n",
      "Power: 62 W\n",
      "Voltage: 120-277, 10 V\n",
      "Lumens: 547091 lm\n",
      "Efficacy: 126.1 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Spelta_CBRL_27W_5000K_DY_TDS.pdf...\n",
      "Extracted Summary for Spelta_CBRL_27W_5000K_DY_TDS.pdf:\n",
      "Power: 27 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.30 A\n",
      "Lumens: 554891 lm\n",
      "Efficacy: 120 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Spelta_CBRL_36W_5000K_DY_TDS.pdf...\n",
      "Extracted Summary for Spelta_CBRL_36W_5000K_DY_TDS.pdf:\n",
      "Power: 36 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.40 A\n",
      "Lumens: 557274 lm\n",
      "Efficacy: 120 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing Striza_MSL_4'_White_20W_4000K_2 Strip_100-277V_TDS.pdf...\n",
      "Extracted Summary for Striza_MSL_4'_White_20W_4000K_2 Strip_100-277V_TDS.pdf:\n",
      "Power: 18, 40, 20, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.22 A\n",
      "Efficacy: 110 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing Striza_MSL_4'_White_20W_5000K_2 Strip_100-277V_TDS.pdf...\n",
      "Extracted Summary for Striza_MSL_4'_White_20W_5000K_2 Strip_100-277V_TDS.pdf:\n",
      "Power: 18, 40, 20, 10 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.22 A\n",
      "Efficacy: 118 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_2FT_9W_FR_4000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_2FT_9W_FR_4000K_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 160 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_2FT_9W_FR_5000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_2FT_9W_FR_5000K_TDS.pdf:\n",
      "Power: 9 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 160 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_4FT_15.7W_CL_4000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_4FT_15.7W_CL_4000K_TDS.pdf:\n",
      "Power: 7 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 160.71 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_4FT_15.7W_CL_5000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_4FT_15.7W_CL_5000K_TDS.pdf:\n",
      "Power: 7 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 165.37 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_4FT_23.2W_FR_4000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_4FT_23.2W_FR_4000K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.09 A\n",
      "Efficacy: 134.85 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T5_Tube_Type_B_4FT_23.2W_FR_5000K_TDS.pdf...\n",
      "Extracted Summary for T5_Tube_Type_B_4FT_23.2W_FR_5000K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.09 A\n",
      "Efficacy: 137.93 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Glass_Tube_Type B_42W_8FT_TDS.pdf...\n",
      "Extracted Summary for T8_Glass_Tube_Type B_42W_8FT_TDS.pdf:\n",
      "Power: 42 W\n",
      "Voltage: 120-277, 100-277 V\n",
      "Current: 0.17 A\n",
      "Efficacy: 119.8 lm/W\n",
      "CCT: 6500, 4000, 5000, 3000, 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_3000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_3000K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_3000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_3000K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_3500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_3500K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_3500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_3500K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_4000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_4000K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_4000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_4000K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_4500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_4500K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_4500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_4500K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_5000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_5000K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_5000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_5000K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_6500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_6500K_SC_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_14W_6500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_14W_6500K_SF_TDS.pdf:\n",
      "Power: 14 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 129 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_3000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_3000K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_3000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_3000K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_3500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_3500K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_3500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_3500K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_4000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_4000K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_4000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_4000K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_4500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_4500K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_4500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_4500K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_5000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_5000K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_5000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_5000K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_6500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_6500K_SC_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_17W_6500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_17W_6500K_SF_TDS.pdf:\n",
      "Power: 17 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 128 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_3000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_3000K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_3000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_3000K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_3500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_3500K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_3500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_3500K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_4000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_4000K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_4000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_4000K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_4500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_4500K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_4500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_4500K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_5000K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_5000K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_5000K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_5000K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_6500K_SC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_6500K_SC_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 150 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_A&B_4FT_18W_6500K_SF_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_A&B_4FT_18W_6500K_SF_TDS.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 135 lm/W\n",
      "CCT: 6500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_2FT_9.2W_FR_3000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_2FT_9.2W_FR_3000K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 154.3 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_2FT_9.2W_FR_3500K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_2FT_9.2W_FR_3500K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 156.25 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_2FT_9.2W_FR_4000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_2FT_9.2W_FR_4000K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 158.2 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_2FT_9.2W_FR_5000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_2FT_9.2W_FR_5000K_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.04 A\n",
      "Efficacy: 162.1 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_3FT_15.3W_CL_4000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_3FT_15.3W_CL_4000K_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 166.78 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_3FT_15.3W_CL_5000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_3FT_15.3W_CL_5000K_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 169.07 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_3FT_15.3W_FR_4000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_3FT_15.3W_FR_4000K_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 161.93 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_3FT_15.3W_FR_5000K_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_3FT_15.3W_FR_5000K_TDS.pdf:\n",
      "Power: 3 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 165.86 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.1W_3500K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.1W_3500K_SF_DLC_TDS.pdf:\n",
      "Power: 1 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05, 0.48 A\n",
      "Efficacy: 150.12 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.1W_4000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.1W_4000K_SF_DLC_TDS.pdf:\n",
      "Power: 1 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 150.87 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.1W_4500K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.1W_4500K_SF_DLC_TDS.pdf:\n",
      "Power: 1 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 151.7 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.1W_5000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.1W_5000K_SF_DLC_TDS.pdf:\n",
      "Power: 1 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 152.52 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.2W_3000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.2W_3000K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 148.49 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.4W_3000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.4W_3000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 154.58 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.4W_3500K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.4W_3500K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 154.98 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.4W_4000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.4W_4000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 156.27 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.4W_4500K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.4W_4500K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 157.64 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_12.4W_5000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_12.4W_5000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.05 A\n",
      "Efficacy: 159 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15.2 W_3000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15.2 W_3000K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 155.88 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15.2 W_3500K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15.2 W_3500K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 157.75 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15.2 W_4000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15.2 W_4000K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 159.78 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15.2 W_4500K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15.2 W_4500K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 161.8 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15.2 W_5000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15.2 W_5000K_SF_DLC_TDS.pdf:\n",
      "Power: 2 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 163.83 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15W_3000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15W_3000K_SC_DLC_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 157.75 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15W_3500K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15W_3500K_SC_DLC_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 159.64 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15W_4500K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15W_4500K_SC_DLC_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 163.75 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_15W_5000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_15W_5000K_SC_DLC_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 165.8 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_17.8W_3000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_17.8W_3000K_SF_DLC_TDS.pdf:\n",
      "Power: 8 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 153.64 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18 W_3500K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18 W_3500K_SF_DLC_TDS.pdf:\n",
      "Power: 18 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 154.34 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18 W_4000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18 W_4000K_SF_DLC_TDS.pdf:\n",
      "Power: 18 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 156.12 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18 W_5000K_SF_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18 W_5000K_SF_DLC_TDS.pdf:\n",
      "Power: 18 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 159.63 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18.4 W_3000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18.4 W_3000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 155.5 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18.4 W_3500K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18.4 W_3500K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 157.37 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18.4 W_4000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18.4 W_4000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 159.39 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_B_4FT_18.4 W_5000K_SC_DLC_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_B_4FT_18.4 W_5000K_SC_DLC_TDS.pdf:\n",
      "Power: 4 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.07 A\n",
      "Efficacy: 163.43 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_3000K_CL_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_3000K_CL_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_3000K_FR_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_3000K_FR_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 130 lm/W\n",
      "CCT: 3000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_3500K_CL_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_3500K_CL_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 141 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_3500K_FR_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_3500K_FR_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 131 lm/W\n",
      "CCT: 3500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_4000K_CL_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_4000K_CL_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 141 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_4000K_FR_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_4000K_FR_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 131 lm/W\n",
      "CCT: 4000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_4500K_CL_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_4500K_CL_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 141 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_4500K_FR_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_4500K_FR_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 132 lm/W\n",
      "CCT: 4500 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_5000K_CL_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_5000K_CL_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 141 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_4FT_15W_5000K_FR_TDS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_4FT_15W_5000K_FR_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 132 lm/W\n",
      "CCT: 5000 K\n",
      "\n",
      "\n",
      "Processing T8_Tube_Type_C_PS.pdf...\n",
      "Extracted Summary for T8_Tube_Type_C_PS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 100-277, 10 V\n",
      "Efficacy: 131, 132, 141 lm/W\n",
      "CCT: 4500, 4000, 5000, 3000, 3500 K\n",
      "\n",
      "\n",
      "Processing T8_U-Bend_Glass_Tube_Type B_TDS.pdf...\n",
      "Extracted Summary for T8_U-Bend_Glass_Tube_Type B_TDS.pdf:\n",
      "Power: 15 W\n",
      "Voltage: 120-277, 10 V\n",
      "Current: 0.06 A\n",
      "Efficacy: 133.3 lm/W\n",
      "CCT: 6500, 4000, 5000, 3000, 3500 K\n",
      "\n",
      "\n",
      "Processing Upstar_UHB_100W150W200W240W_Black_TDS.pdf...\n",
      "Extracted Summary for Upstar_UHB_100W150W200W240W_Black_TDS.pdf:\n",
      "Power: 2, 240 W\n",
      "Voltage: 120-277 V\n",
      "Current: 0.99 A\n",
      "Lumens: 482255 lm\n",
      "Efficacy: 131.48 lm/W\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing Vaso Explosion Proof Jelly Jar Light.pdf...\n",
      "Extracted Summary for Vaso Explosion Proof Jelly Jar Light.pdf:\n",
      "Power: 20 W\n",
      "Voltage: 100-277 V\n",
      "Current: 0.12, 0.08, 0.16 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Victoris Explosion Proof Linear High Bay.pdf...\n",
      "Extracted Summary for Victoris Explosion Proof Linear High Bay.pdf:\n",
      "Power: 40, 20, 80, 60 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 0.24, 0.32, 0.08, 0.16 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "\n",
      "Processing Vigor Explosion Proof Round High Bay (1).pdf...\n",
      "Extracted Summary for Vigor Explosion Proof Round High Bay (1).pdf:\n",
      "Power: 150, 40, 400, 100, 200, 250, 80, 20, 60 W\n",
      "Voltage: 200-480, 100-277 V\n",
      "Current: 0.80, 0.24, 0.40, 0.32, 0.60, 0.16, 1.00, 0.08, 1.60 A\n",
      "Efficacy: 140 lm/W\n",
      "CCT: 5000, 4000 K\n",
      "\n",
      "PDFs from Vendor Lights folder:\n",
      "\n",
      "Processing configurable-cpx.pdf...\n",
      "Extracted Summary for configurable-cpx.pdf:\n",
      "Power: 20, 15, 7, 10 W\n",
      "Voltage: 120-277, 347, 10, 277, 120 V\n",
      "Lumens: 2000, 10000, 4000, 7200, 3200, 5000, 3000, 120, 6000, 8500 lm\n",
      "CCT: 3000, 4000, 3500 K\n",
      "\n",
      "\n",
      "Processing lbk-configurable.pdf...\n",
      "Extracted Summary for lbk-configurable.pdf:\n",
      "Power: 3, 13, 77, 0, 1, 4, 5, 15, 20, 9, 10, 7, 2, 6, 51, 39, 26 W\n",
      "Voltage: 120-277, 347, 10 V\n",
      "Lumens: 120 lm\n",
      "CCT: 5000, 4000, 3500 K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Only add text if extraction was successful\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "# Step 2: Clean the extracted text by removing unnecessary formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces/newlines with single space\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    return text.strip()\n",
    "\n",
    "# Step 3: Extract specific data (Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angle) using regex\n",
    "def extract_specifications(text):\n",
    "    # Patterns to match Power, Voltage, Current, Lumens, Efficacy, CCT, Beam Angles\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'\n",
    "    voltage_pattern = r'(\\d{2,3})\\s*-\\s*(\\d{2,3})\\s*V|\\b(\\d{1,3})\\s*V\\b'\n",
    "    current_pattern = r'(\\d{1,3}\\.\\d{1,3})\\s*A'\n",
    "    lumens_pattern = r'(\\d{3,6}(\\.\\d+)?)\\s*Lumens?\\b'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4}\\.\\d+|\\d{2,4})\\s*lm/W\\b'\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'\n",
    "\n",
    "    # Extract data using regex\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    # Process voltage to handle range (e.g., 120-277 V)\n",
    "    voltage_ranges = []\n",
    "    for volt in voltage:\n",
    "        if volt[0] and volt[1]:\n",
    "            voltage_ranges.append(f\"{volt[0]}-{volt[1]}\")\n",
    "        elif volt[2]:\n",
    "            voltage_ranges.append(volt[2])\n",
    "\n",
    "    # Remove duplicates by converting lists to sets and then back to lists\n",
    "    extracted_data = {\n",
    "        \"Power (W)\": list(set(power)),\n",
    "        \"Voltage (V)\": list(set(voltage_ranges)),\n",
    "        \"Current (A)\": list(set(current)),\n",
    "        \"Lumens\": list(set([lum[0] for lum in lumens])),\n",
    "        \"Efficacy (lm/W)\": list(set(efficacy)),\n",
    "        \"CCT (K)\": list(set(cct)),\n",
    "        \"Beam Angles ()\": list(set(beam_angles))\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Step 4: Summarize the extracted data\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])} lm\\n\"\n",
    "    \n",
    "    if extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angle: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Step 5: Process PDFs in a specific folder\n",
    "def process_pdfs_in_folder(folder_path, folder_name):\n",
    "    print(f\"PDFs from {folder_name} folder:\")\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        print(f\"\\nProcessing {pdf_file}...\")\n",
    "        \n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        extracted_data = extract_specifications(pdf_text)\n",
    "        summary = summarize_extracted_data(extracted_data)\n",
    "        \n",
    "        print(f\"Extracted Summary for {pdf_file}:\\n{summary}\\n\")\n",
    "\n",
    "# Step 6: Execute the pipeline for both folders\n",
    "ikio_lights_folder = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Update this to your IKIO folder path\n",
    "vendor_lights_folder = \"D://Cross Search Automation//Previous Cross//Vendor Lights\"  # Update this to your Vendor folder path\n",
    "\n",
    "# Process PDFs in both folders\n",
    "process_pdfs_in_folder(ikio_lights_folder, \"IKIO Lights\")\n",
    "process_pdfs_in_folder(vendor_lights_folder, \"Vendor Lights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3e45f-5679-4884-8d8c-a19a1d02e754",
   "metadata": {},
   "source": [
    "Now we are able to extract the exact data from the pdf's of the specific mentioned parameters. We will now integrate this with the image similarity to give the data of the 2 pdf's after the image similarity is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09c311-c7a5-44b5-b125-3310ae61d38d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ad234-61a7-4a0a-a411-9e4d645e6f48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a0f41-60e9-4a3b-ae07-a87ecd85a41a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f6b151-f28b-4a5e-9564-f2514e52991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the most similar PDFs based on image similarity...\n",
      "\n",
      "Top similar PDFs:\n",
      "Orwin_DL_10inch_TDS.pdf: Similarity Score = 0.5200\n",
      "Orwin_DL_6inch_TDS.pdf: Similarity Score = 0.5200\n",
      "\n",
      "Extracting and summarizing data from PDFs...\n",
      "\n",
      "PDF: Orwin_DL_10inch_TDS.pdf\n",
      "Power: 18, 22, 30, 38 W\n",
      "Voltage: 10, 120-277 V\n",
      "Current: 0.14 A\n",
      "Efficacy: 89.11, 91.50, 93.83 lm/W\n",
      "CCT: 2700, 3000, 3500, 4000, 5000 K\n",
      "--------------------------------------------------\n",
      "PDF: Orwin_DL_6inch_TDS.pdf\n",
      "Power: 12, 17, 18, 22 W\n",
      "Voltage: 10, 120-277 V\n",
      "Current: 0.08 A\n",
      "Efficacy: 84.68, 87.50, 90.24 lm/W\n",
      "CCT: 2700, 3000, 3500, 4000, 5000 K\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Load the pre-trained VGG-19 and ResNet models\n",
    "vgg_model = models.vgg19(pretrained=True)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "vgg_model.eval()\n",
    "resnet_model.eval()\n",
    "\n",
    "# Image preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Program 1: Image Similarity Functions\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_intermediate_features(image, model, layer):\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['output'] = output\n",
    "\n",
    "    handle = model._modules.get(layer).register_forward_hook(hook_fn)\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    intermediate_features = activation['output']\n",
    "    handle.remove()\n",
    "\n",
    "    return intermediate_features.flatten().numpy()\n",
    "\n",
    "def extract_resnet_features(image):\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        resnet_features = resnet_model(input_tensor)\n",
    "    return resnet_features.flatten().numpy()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extract combined VGG, ResNet, and HOG features.\"\"\"\n",
    "    vgg_features = extract_intermediate_features(image, vgg_model, 'features')\n",
    "    resnet_features = extract_resnet_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "\n",
    "    vgg_weight = 0.5\n",
    "    resnet_weight = 0.3\n",
    "    hog_weight = 0.2\n",
    "\n",
    "    combined_features = np.concatenate([\n",
    "        vgg_features * vgg_weight, \n",
    "        resnet_features * resnet_weight, \n",
    "        hog_features * hog_weight\n",
    "    ])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = image.resize((128, 128))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "\n",
    "    hog_features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(1, 1), visualize=False, feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    if features1.size == 0 or features2.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    features1 = features1.reshape(1, -1)\n",
    "    features2 = features2.reshape(1, -1)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((300, 300))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "def find_top_similar_pdfs(input_image_path, folder_path, top_n=2):\n",
    "    input_image = Image.open(input_image_path)\n",
    "\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "\n",
    "    pdf_similarity_scores = []\n",
    "\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "            for img in extracted_images:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "\n",
    "                img_features = extract_image_features(img)\n",
    "                similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "                keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "                combined_score = (0.7 * similarity + 0.3 * (keypoint_match_count / 1000))\n",
    "\n",
    "                pdf_similarity_scores.append((pdf_file, combined_score))\n",
    "\n",
    "    pdf_similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar_pdfs = pdf_similarity_scores[:top_n]\n",
    "\n",
    "    return top_similar_pdfs\n",
    "\n",
    "# Program 2: PDF Data Extraction Functions\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_specifications(text):\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'\n",
    "    voltage_pattern = r'(\\d{2,3})\\s*-\\s*(\\d{2,3})\\s*V|\\b(\\d{1,3})\\s*V\\b'\n",
    "    current_pattern = r'(\\d{1,3}\\.\\d{1,3})\\s*A'\n",
    "    lumens_pattern = r'(\\d{3,6}(\\.\\d+)?)\\s*Lumens?\\b'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4}\\.\\d+|\\d{2,4})\\s*lm/W\\b'\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'\n",
    "\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    voltage_ranges = []\n",
    "    for volt in voltage:\n",
    "        if volt[0] and volt[1]:\n",
    "            voltage_ranges.append(f\"{volt[0]}-{volt[1]}\")\n",
    "        elif volt[2]:\n",
    "            voltage_ranges.append(volt[2])\n",
    "\n",
    "    extracted_data = {\n",
    "        \"Power (W)\": sorted(set(power), key=int),\n",
    "        \"Voltage (V)\": sorted(set(voltage_ranges), key=lambda x: int(x.split('-')[0]) if '-' in x else int(x)),\n",
    "        \"Current (A)\": sorted(set(current), key=float),\n",
    "        \"Lumens\": sorted(set([lum[0] for lum in lumens]), key=float),\n",
    "        \"Efficacy (lm/W)\": sorted(set(efficacy), key=float),\n",
    "        \"CCT (K)\": sorted(set(cct), key=int),\n",
    "        \"Beam Angles ()\": sorted(set(beam_angles), key=int)\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])} lm\\n\"\n",
    "    \n",
    "    if extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angle: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# Main Function\n",
    "def main(input_image_path, pdf_folder_path):\n",
    "    # Step 1: Find the most similar PDFs\n",
    "    print(\"Finding the most similar PDFs based on image similarity...\\n\")\n",
    "    top_similar_pdfs = find_top_similar_pdfs(input_image_path, pdf_folder_path)\n",
    "    \n",
    "    print(\"Top similar PDFs:\")\n",
    "    for pdf_file, score in top_similar_pdfs:\n",
    "        print(f\"{pdf_file}: Similarity Score = {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nExtracting and summarizing data from PDFs...\\n\")\n",
    "\n",
    "    # Step 2: Extract and summarize specifications from PDFs\n",
    "    for pdf_file, _ in top_similar_pdfs:\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        extracted_data = extract_specifications(pdf_text)\n",
    "        summary = summarize_extracted_data(extracted_data)\n",
    "\n",
    "        print(f\"PDF: {pdf_file}\\n{summary}\\n{'-'*50}\")\n",
    "\n",
    "# Example usage\n",
    "input_image_path = \"D://Cross Search Automation//Previous Cross//Vendor Lights//test3.JPG\"  # Your input image path\n",
    "pdf_folder_path = \"D://Cross Search Automation//Previous Cross//IKIO Lights\"  # Your folder path containing PDFs\n",
    "main(input_image_path, pdf_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909766c1-7df6-4074-8983-93bcf4b510cf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fec9db-e0c1-4038-b921-ac83b65f555c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41bb23-a511-4d5a-a1ba-fcc333d6cee4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70db673-61c8-4610-aabc-7856fe056b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "import PyPDF2\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "from threading import Thread\n",
    "\n",
    "# Load the pre-trained VGG-19 and ResNet models\n",
    "vgg_model = models.vgg19(pretrained=True)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "vgg_model.eval()\n",
    "resnet_model.eval()\n",
    "\n",
    "# Image preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Program 1: Image Similarity Functions\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    images = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            images.append(image)\n",
    "\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "def extract_intermediate_features(image, model, layer):\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['output'] = output\n",
    "\n",
    "    handle = model._modules.get(layer).register_forward_hook(hook_fn)\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    intermediate_features = activation['output']\n",
    "    handle.remove()\n",
    "\n",
    "    return intermediate_features.flatten().numpy()\n",
    "\n",
    "def extract_resnet_features(image):\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        resnet_features = resnet_model(input_tensor)\n",
    "    return resnet_features.flatten().numpy()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\"Extract combined VGG, ResNet, and HOG features.\"\"\"\n",
    "    vgg_features = extract_intermediate_features(image, vgg_model, 'features')\n",
    "    resnet_features = extract_resnet_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "\n",
    "    vgg_weight = 0.5\n",
    "    resnet_weight = 0.3\n",
    "    hog_weight = 0.2\n",
    "\n",
    "    combined_features = np.concatenate([\n",
    "        vgg_features * vgg_weight, \n",
    "        resnet_features * resnet_weight, \n",
    "        hog_features * hog_weight\n",
    "    ])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = image.resize((128, 128))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "\n",
    "    hog_features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(1, 1), visualize=False, feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "def calculate_image_similarity(features1, features2):\n",
    "    if features1.size == 0 or features2.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    features1 = features1.reshape(1, -1)\n",
    "    features2 = features2.reshape(1, -1)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((300, 300))\n",
    "    image_np = np.array(image)\n",
    "    gray_image = rgb2gray(image_np)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    return gray_image\n",
    "\n",
    "def match_keypoints(image1, image2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    image1_gray = preprocess_image(image1)\n",
    "    image2_gray = preprocess_image(image2)\n",
    "\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2_gray, None)\n",
    "\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return 0\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "def find_top_similar_pdfs(input_image_path, folder_path, update_progress=None, top_n=2):\n",
    "    input_image = Image.open(input_image_path)\n",
    "\n",
    "    if input_image.mode != 'RGB':\n",
    "        input_image = input_image.convert('RGB')\n",
    "\n",
    "    input_image_features = extract_image_features(input_image)\n",
    "\n",
    "    pdf_similarity_scores = []\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "    total_pdfs = len(pdf_files)\n",
    "\n",
    "    for idx, pdf_file in enumerate(pdf_files):\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        extracted_images = extract_images_from_pdf(pdf_path)\n",
    "\n",
    "        for img in extracted_images:\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            img_features = extract_image_features(img)\n",
    "            similarity = calculate_image_similarity(input_image_features, img_features)\n",
    "            keypoint_match_count = match_keypoints(input_image, img)\n",
    "\n",
    "            combined_score = (0.7 * similarity + 0.3 * (keypoint_match_count / 1000))\n",
    "\n",
    "            pdf_similarity_scores.append((pdf_file, combined_score))\n",
    "\n",
    "        if update_progress:\n",
    "            update_progress(idx + 1, total_pdfs)\n",
    "\n",
    "    pdf_similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_similar_pdfs = pdf_similarity_scores[:top_n]\n",
    "\n",
    "    return top_similar_pdfs\n",
    "\n",
    "# Program 2: PDF Data Extraction Functions\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "    return clean_text(text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_specifications(text):\n",
    "    power_pattern = r'\\b(\\d{1,4})\\s*W\\b'\n",
    "    voltage_pattern = r'(\\d{2,3})\\s*-\\s*(\\d{2,3})\\s*V|\\b(\\d{1,3})\\s*V\\b'\n",
    "    current_pattern = r'(\\d{1,3}\\.\\d{1,3})\\s*A'\n",
    "    lumens_pattern = r'(\\d{3,6}(\\.\\d+)?)\\s*Lumens?\\b'\n",
    "    efficacy_pattern = r'\\b(\\d{2,4}\\.\\d+|\\d{2,4})\\s*lm/W\\b'\n",
    "    cct_pattern = r'\\b(\\d{4})\\s*K\\b'\n",
    "    beam_angle_pattern = r'\\b(\\d{1,3})\\s*[]\\b'\n",
    "\n",
    "    power = re.findall(power_pattern, text)\n",
    "    voltage = re.findall(voltage_pattern, text)\n",
    "    current = re.findall(current_pattern, text)\n",
    "    lumens = re.findall(lumens_pattern, text)\n",
    "    efficacy = re.findall(efficacy_pattern, text)\n",
    "    cct = re.findall(cct_pattern, text)\n",
    "    beam_angles = re.findall(beam_angle_pattern, text)\n",
    "\n",
    "    voltage_ranges = []\n",
    "    for volt in voltage:\n",
    "        if volt[0] and volt[1]:\n",
    "            voltage_ranges.append(f\"{volt[0]}-{volt[1]}\")\n",
    "        elif volt[2]:\n",
    "            voltage_ranges.append(volt[2])\n",
    "\n",
    "    extracted_data = {\n",
    "        \"Power (W)\": sorted(set(power), key=int),\n",
    "        \"Voltage (V)\": sorted(set(voltage_ranges), key=lambda x: int(x.split('-')[0]) if '-' in x else int(x)),\n",
    "        \"Current (A)\": sorted(set(current), key=float),\n",
    "        \"Lumens\": sorted(set([lum[0] for lum in lumens]), key=float),\n",
    "        \"Efficacy (lm/W)\": sorted(set(efficacy), key=float),\n",
    "        \"CCT (K)\": sorted(set(cct), key=int),\n",
    "        \"Beam Angles ()\": sorted(set(beam_angles), key=int)\n",
    "    }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def summarize_extracted_data(extracted_data):\n",
    "    summary = \"\"\n",
    "    \n",
    "    if extracted_data[\"Power (W)\"]:\n",
    "        summary += f\"Power: {', '.join(extracted_data['Power (W)'])} W\\n\"\n",
    "    \n",
    "    if extracted_data[\"Voltage (V)\"]:\n",
    "        summary += f\"Voltage: {', '.join(extracted_data['Voltage (V)'])} V\\n\"\n",
    "    \n",
    "    if extracted_data[\"Current (A)\"]:\n",
    "        summary += f\"Current: {', '.join(extracted_data['Current (A)'])} A\\n\"\n",
    "    \n",
    "    if extracted_data[\"Lumens\"]:\n",
    "        summary += f\"Lumens: {', '.join(extracted_data['Lumens'])} lm\\n\"\n",
    "    \n",
    "    if extracted_data[\"Efficacy (lm/W)\"]:\n",
    "        summary += f\"Efficacy: {', '.join(extracted_data['Efficacy (lm/W)'])} lm/W\\n\"\n",
    "    \n",
    "    if extracted_data[\"CCT (K)\"]:\n",
    "        summary += f\"CCT: {', '.join(extracted_data['CCT (K)'])} K\\n\"\n",
    "    \n",
    "    if extracted_data[\"Beam Angles ()\"]:\n",
    "        summary += f\"Beam Angle: {', '.join(extracted_data['Beam Angles ()'])}\\n\"\n",
    "    \n",
    "    return summary.strip()\n",
    "\n",
    "# UI code\n",
    "class PDFComparisonApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"PDF Comparison Tool\")\n",
    "\n",
    "        # Create UI elements\n",
    "        self.label_image_path = tk.Label(root, text=\"Input Image Path:\")\n",
    "        self.label_image_path.grid(row=0, column=0, padx=10, pady=5)\n",
    "        self.entry_image_path = tk.Entry(root, width=50)\n",
    "        self.entry_image_path.grid(row=0, column=1, padx=10, pady=5)\n",
    "        self.button_browse_image = tk.Button(root, text=\"Browse\", command=self.browse_image)\n",
    "        self.button_browse_image.grid(row=0, column=2, padx=10, pady=5)\n",
    "\n",
    "        self.label_pdf_folder_path = tk.Label(root, text=\"PDF Folder Path:\")\n",
    "        self.label_pdf_folder_path.grid(row=1, column=0, padx=10, pady=5)\n",
    "        self.entry_pdf_folder_path = tk.Entry(root, width=50)\n",
    "        self.entry_pdf_folder_path.grid(row=1, column=1, padx=10, pady=5)\n",
    "        self.button_browse_pdf_folder = tk.Button(root, text=\"Browse\", command=self.browse_pdf_folder)\n",
    "        self.button_browse_pdf_folder.grid(row=1, column=2, padx=10, pady=5)\n",
    "\n",
    "        self.label_compare_pdf_path = tk.Label(root, text=\"PDF to Compare:\")\n",
    "        self.label_compare_pdf_path.grid(row=2, column=0, padx=10, pady=5)\n",
    "        self.entry_compare_pdf_path = tk.Entry(root, width=50)\n",
    "        self.entry_compare_pdf_path.grid(row=2, column=1, padx=10, pady=5)\n",
    "        self.button_browse_compare_pdf = tk.Button(root, text=\"Browse\", command=self.browse_compare_pdf)\n",
    "        self.button_browse_compare_pdf.grid(row=2, column=2, padx=10, pady=5)\n",
    "\n",
    "        self.button_run = tk.Button(root, text=\"Run\", command=self.run)\n",
    "        self.button_run.grid(row=3, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "        self.progress = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(root, length=400, variable=self.progress, maximum=100)\n",
    "        self.progress_bar.grid(row=4, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "        self.label_progress = tk.Label(root, text=\"Progress:\")\n",
    "        self.label_progress.grid(row=5, column=0, padx=10, pady=5)\n",
    "        self.label_percentage = tk.Label(root, text=\"0%\")\n",
    "        self.label_percentage.grid(row=5, column=1, padx=10, pady=5)\n",
    "\n",
    "        self.result_text = tk.Text(root, height=20, width=80)\n",
    "        self.result_text.grid(row=6, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "    def browse_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            self.entry_image_path.delete(0, tk.END)\n",
    "            self.entry_image_path.insert(0, file_path)\n",
    "\n",
    "    def browse_pdf_folder(self):\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        if folder_path:\n",
    "            self.entry_pdf_folder_path.delete(0, tk.END)\n",
    "            self.entry_pdf_folder_path.insert(0, folder_path)\n",
    "\n",
    "    def browse_compare_pdf(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "        if file_path:\n",
    "            self.entry_compare_pdf_path.delete(0, tk.END)\n",
    "            self.entry_compare_pdf_path.insert(0, file_path)\n",
    "\n",
    "    def run(self):\n",
    "        image_path = self.entry_image_path.get()\n",
    "        pdf_folder_path = self.entry_pdf_folder_path.get()\n",
    "        compare_pdf_path = self.entry_compare_pdf_path.get()\n",
    "\n",
    "        if not os.path.isfile(image_path) or not os.path.isdir(pdf_folder_path) or not os.path.isfile(compare_pdf_path):\n",
    "            messagebox.showerror(\"Error\", \"Please provide valid paths for all inputs.\")\n",
    "            return\n",
    "\n",
    "        self.result_text.delete(1.0, tk.END)\n",
    "        self.progress.set(0)\n",
    "        self.label_percentage.config(text=\"0%\")\n",
    "\n",
    "        def update_progress(current, total):\n",
    "            percentage = (current / total) * 100\n",
    "            self.progress.set(percentage)\n",
    "            self.label_percentage.config(text=f\"{int(percentage)}%\")\n",
    "            self.root.update_idletasks()\n",
    "\n",
    "        def run_task():\n",
    "            try:\n",
    "                top_similar_pdfs = find_top_similar_pdfs(image_path, pdf_folder_path, update_progress)\n",
    "\n",
    "                self.result_text.insert(tk.END, \"Top similar PDFs:\\n\")\n",
    "                for pdf_file, score in top_similar_pdfs:\n",
    "                    self.result_text.insert(tk.END, f\"{pdf_file}: Similarity Score = {score:.4f}\\n\")\n",
    "\n",
    "                pdf_summaries = {}\n",
    "                for pdf_file, _ in top_similar_pdfs:\n",
    "                    pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "                    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "                    extracted_data = extract_specifications(pdf_text)\n",
    "                    summary = summarize_extracted_data(extracted_data)\n",
    "                    pdf_summaries[pdf_file] = summary\n",
    "\n",
    "                self.result_text.insert(tk.END, \"\\nSummaries of shortlisted PDFs:\\n\")\n",
    "                for pdf_file, summary in pdf_summaries.items():\n",
    "                    self.result_text.insert(tk.END, f\"PDF: {pdf_file}\\n{summary}\\n{'-'*50}\\n\")\n",
    "\n",
    "                user_pdf_text = extract_text_from_pdf(compare_pdf_path)\n",
    "                user_extracted_data = extract_specifications(user_pdf_text)\n",
    "                user_summary = summarize_extracted_data(user_extracted_data)\n",
    "\n",
    "                self.result_text.insert(tk.END, f\"\\nUser-provided PDF Summary:\\n{user_summary}\\n{'-'*50}\\n\")\n",
    "\n",
    "                self.result_text.insert(tk.END, \"\\nComparing user PDF with shortlisted PDFs:\\n\")\n",
    "                for pdf_file, summary in pdf_summaries.items():\n",
    "                    self.result_text.insert(tk.END, f\"Comparing with PDF: {pdf_file}\\n\")\n",
    "                    for key, value in user_extracted_data.items():\n",
    "                        if key in extracted_data:\n",
    "                            common_values = set(value).intersection(set(extracted_data[key]))\n",
    "                            if common_values:\n",
    "                                self.result_text.insert(tk.END, f\"Common {key}: {', '.join(common_values)}\\n\")\n",
    "                            else:\n",
    "                                self.result_text.insert(tk.END, f\"No common {key} found.\\n\")\n",
    "\n",
    "                self.result_text.insert(tk.END, \"\\nProcessing complete.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "        thread = Thread(target=run_task)\n",
    "        thread.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PDFComparisonApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbfe1a-7768-4930-aabd-130cc28f044b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
